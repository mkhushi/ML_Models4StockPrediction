{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "otETlYbGYEHj"
   },
   "source": [
    "# COMP5703 - Capstone project CP-14 ---->\n",
    "\n",
    "Original author: Pote Pongchaikul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_tDQWgedvbss"
   },
   "source": [
    "## Preface\n",
    "\n",
    "The code was originally designed for training on one dataset (containing many stocks) and testing on another data (again multi-stock)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "goWX1jkHFvir"
   },
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XrVmOp9Z-NxB"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive\n",
    "\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# 1. Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# PyDrive reference:\n",
    "# https://googledrive.github.io/PyDrive/docs/build/html/index.html\n",
    "# https://pythonhosted.org/PyDrive/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "gi_ECHAc-kHT",
    "outputId": "2a51da37-bcc8-4b8f-852c-bd25a58dadb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: MAIN edition COMP5703 project code.ipynb, id: 1IwGrPx0ScQ1z0B3OOy5EBisvDTGbM-iT\n",
      "title: test MAIN.ipynb, id: 1vjNKndUIkQZ6SQZsxRs0I_OkdaCdI3Ad\n",
      "title: ASX200_ASX50 edition COMP5703 project code.ipynb, id: 1CXNmMURZodOrqdZOj0ltMyuBzbAdY9lJ\n",
      "title: COMP5703 Project code 1.ipynb, id: 1hDXK8bn-zpmzGzvIXBddWhSohkY0yEN6\n",
      "title: INDEX version of project code.ipynb, id: 1H8FzkIRn8Jk7TAHcA0rs7gYog7PhhrIO\n",
      "title: Project timeline, id: 1Hg82YX1iJozlaclxmHSCxqrVplQh81HYfyL1Hw4BZU4\n",
      "title: Capstone_Create_Datasets_27Aug18.ipynb, id: 1anV2YNGlCdiL3tBRUa5G7uNkmVWPDPkW\n",
      "title: Scribble notes, id: 1AyZhQVkclpd0NqWdU02yM23gELcRDLYV8iU-1FXeni0\n",
      "title: OLD, id: 1bKKKo4QNg1omQ_ejH3_ntUu_EMwLJvv-\n"
     ]
    }
   ],
   "source": [
    "file_list = drive.ListFile({'q': \"'1mWlUOJaz6IPibDYVw8Oz1Ps_04hNwJSu' in parents and trashed=false\"}).GetList()\n",
    "for file1 in file_list:\n",
    "  print('title: %s, id: %s' % (file1['title'], file1['id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJpHSBHGF1OB"
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "YSzZOQhMABvo",
    "outputId": "b21b9543-b25b-4292-9d77-d656e2a54c27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydlm\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/eb/09e3cfb7e5326b4240e9c92cd1639202e1f5c7af14b87bbf65bb76c7f7e2/pydlm-0.1.1.10.tar.gz (43kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 1.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pydlm) (1.14.6)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from pydlm) (2.1.2)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pydlm) (1.11.0)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib->pydlm) (2018.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pydlm) (2.5.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pydlm) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pydlm) (2.2.1)\n",
      "Building wheels for collected packages: pydlm\n",
      "  Running setup.py bdist_wheel for pydlm ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d3/64/7f/99427e6464ff5f8561889ab4f001422a69e1f59636790b9f91\n",
      "Successfully built pydlm\n",
      "Installing collected packages: pydlm\n",
      "Successfully installed pydlm-0.1.1.10\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.7.1)\n",
      "Collecting wbdata\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/a0/c83a8cb001885685f8344f4a6d3557ec3de73d367aea82dbb519aa6d2706/wbdata-0.2.7.tar.gz\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from wbdata) (4.3.0)\n",
      "Building wheels for collected packages: wbdata\n",
      "  Running setup.py bdist_wheel for wbdata ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/57/61/6a/3978e90cf2f9443b94ce56b4fa839850da9076e697be3a27e3\n",
      "Successfully built wbdata\n",
      "Installing collected packages: wbdata\n",
      "Successfully installed wbdata-0.2.7\n"
     ]
    }
   ],
   "source": [
    "## For state space modelling\n",
    "## Ref: https://pydlm.github.io/installation.html, accessed 5 September\n",
    "!pip install pydlm\n",
    "!pip install seaborn\n",
    "!pip install wbdata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T0yjv69B_wCz"
   },
   "outputs": [],
   "source": [
    "## Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Ref: https://pydlm.github.io/pydlm_user_guide.html#modeling, accessed 5 September\n",
    "from pydlm import dlm, dynamic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J4j-uk7dF7pE"
   },
   "source": [
    "## Import dataset\n",
    "\n",
    "The array dataset_list will be used later to indicate whether we are dealing with training data or testing data. It is also important for adjusted_data_df_original, which will be used as main_data variable later. By default, the first index of dataset_list shall refer to testing data. \n",
    "\n",
    "* adjusted_data_df_original: dictionary that consists of adjusted_data.csv (S&P500 and ASX200) downloaded from github. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ecet3SRi-6ij"
   },
   "outputs": [],
   "source": [
    "## Adjusted data 1: ASX200\n",
    "## Adjusted data 2: S&P500 set 1\n",
    "## Adjusted data 3: S&P500 set 2\n",
    "## Adjusted data 4: S&P500 set 3\n",
    "\n",
    "\n",
    "adjusted_data_ASX = pd.read_csv(\"https://raw.github.sydney.edu.au/asha7190/MI_FinancialTrading/master/Code_old/adjusted_data.csv?token=AAAH4bQYtoFgmMMCIs74ciLBtD3taWFxks5bw_MpwA%3D%3D\",\n",
    "                           index_col=0, parse_dates=True)\n",
    "\n",
    "adjusted_data_SP500_1 = pd.read_csv(\"https://raw.github.sydney.edu.au/asha7190/MI_FinancialTrading/master/Code_old/S%26P500%20Data/sp500_adjusted_data_1.csv?token=AAAH4ffHgmhs-El1ALefeRD0kBuh95fdks5bw_NWwA%3D%3D\",\n",
    "                           index_col=0, parse_dates=True)\n",
    "\n",
    "adjusted_data_SP500_2 = pd.read_csv(\"https://raw.github.sydney.edu.au/asha7190/MI_FinancialTrading/master/Code_old/S%26P500%20Data/sp500_adjusted_data_2.csv?token=AAAH4XXEjrUCX3IsffbgqrhaSaLcwcosks5bw_O4wA%3D%3D\",\n",
    "                           index_col=0, parse_dates=True)\n",
    "\n",
    "adjusted_data_SP500_3 = pd.read_csv(\"https://raw.github.sydney.edu.au/asha7190/MI_FinancialTrading/master/Code_old/S%26P500%20Data/sp500_adjusted_data_3.csv?token=AAAH4fxQy7QhSXOVnBn_KWBRs9GSj573ks5bw_PSwA%3D%3D\",\n",
    "                           index_col=0, parse_dates=True)\n",
    "\n",
    "\n",
    "\n",
    "dataset_list = [\"ASX\",\"SP500_1\",\"SP500_2\",\"SP500_3\"]\n",
    "adjusted_data_df_original = {\"ASX\":adjusted_data_ASX, \"SP500_1\":adjusted_data_SP500_1,\n",
    "                     \"SP500_2\":adjusted_data_SP500_2, \"SP500_3\":adjusted_data_SP500_3}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0Uj6vcVmTtE"
   },
   "source": [
    "We are renaming columns so that capitalization, lower case and upper case letters match that of Dr. Khushi's code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oNUUmSTyNP63"
   },
   "outputs": [],
   "source": [
    "## Rename columns and to drop some columns that appeared redundant\n",
    "\n",
    "for data in dataset_list:\n",
    "  \n",
    "  ## Rename columns:\n",
    "  ## https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rename.html, accessed 3 September\n",
    "  adjusted_data_df_original[data] = adjusted_data_df_original[data].rename(columns = {\"open\":\"Open\",\"high\":\"High\",\"low\":\"Low\",\"close\":\"Close\",\"volume\":\"Volume\"})\n",
    "\n",
    "  ## Drop columns: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html, accessed 16 September\n",
    "  #adjusted_data_df_original[data] = adjusted_data_df_original[data].drop(columns = [\"dividend_amount\",\t\"split_coefficient\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "SHULYIsziYDc",
    "outputId": "57c88353-ed3f-48f2-dd16-33f426a7d543"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>dividend_amount</th>\n",
       "      <th>split_coefficient</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-09-17</th>\n",
       "      <td>89.06</td>\n",
       "      <td>89.2800</td>\n",
       "      <td>88.030</td>\n",
       "      <td>88.30</td>\n",
       "      <td>88.30</td>\n",
       "      <td>1667207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-18</th>\n",
       "      <td>88.17</td>\n",
       "      <td>89.4850</td>\n",
       "      <td>88.150</td>\n",
       "      <td>89.18</td>\n",
       "      <td>89.18</td>\n",
       "      <td>1722348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19</th>\n",
       "      <td>89.14</td>\n",
       "      <td>89.6900</td>\n",
       "      <td>88.790</td>\n",
       "      <td>89.08</td>\n",
       "      <td>89.08</td>\n",
       "      <td>2273387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-20</th>\n",
       "      <td>89.72</td>\n",
       "      <td>90.5000</td>\n",
       "      <td>89.315</td>\n",
       "      <td>90.06</td>\n",
       "      <td>90.06</td>\n",
       "      <td>3428300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-21</th>\n",
       "      <td>90.03</td>\n",
       "      <td>90.9341</td>\n",
       "      <td>89.790</td>\n",
       "      <td>89.83</td>\n",
       "      <td>89.83</td>\n",
       "      <td>3448374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open     High     Low  Close  adjusted_close   Volume  \\\n",
       "date                                                                 \n",
       "2018-09-17  89.06  89.2800  88.030  88.30           88.30  1667207   \n",
       "2018-09-18  88.17  89.4850  88.150  89.18           89.18  1722348   \n",
       "2018-09-19  89.14  89.6900  88.790  89.08           89.08  2273387   \n",
       "2018-09-20  89.72  90.5000  89.315  90.06           90.06  3428300   \n",
       "2018-09-21  90.03  90.9341  89.790  89.83           89.83  3448374   \n",
       "\n",
       "            dividend_amount  split_coefficient symbol  \n",
       "date                                                   \n",
       "2018-09-17              0.0                1.0    ZTS  \n",
       "2018-09-18              0.0                1.0    ZTS  \n",
       "2018-09-19              0.0                1.0    ZTS  \n",
       "2018-09-20              0.0                1.0    ZTS  \n",
       "2018-09-21              0.0                1.0    ZTS  "
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_data_df_original[\"SP500_3\"].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h01a4w95lFXg"
   },
   "source": [
    "### Import and merge World bank data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MJOMVZFuJJzS"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#World Bank API\n",
    "\n",
    "# Data Acquisition\n",
    "\n",
    "# For citation purposes:\n",
    "\n",
    "# Sherouse, Oliver (2014). Wbdata. Arlington, VA. Available from http://github.com/OliverSherouse/wbdata.\n",
    "\n",
    "# Documentation: https://wbdata.readthedocs.io/en/latest/index.html\n",
    "\n",
    "#Load libraries\n",
    "import wbdata\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "#import pandas_datareader.data as web\n",
    "\n",
    "from matplotlib.dates import date2num\n",
    "from matplotlib.dates import num2date\n",
    "import matplotlib.dates as mpld\n",
    "import numpy as np\n",
    "\n",
    "#List of information sources (indicators groups/categories)\n",
    "\n",
    "#wbdata.get_source()\n",
    "\n",
    "\n",
    "#Search indicator code\n",
    "\n",
    "#wbdata.get_indicator(source=6)\n",
    "\n",
    "#Search for countries or indicators\n",
    "#wbdata.search_countries(\"New\")\n",
    "#wbdata.search_indicators(\"debt\")\n",
    "#country_list=wbdata.get_country(display=False)\n",
    "#country_list[0]\n",
    "#all_countries={}\n",
    "#for country in country_list:\n",
    "#    all_countries[country['id']]=country['name']\n",
    "\n",
    "#Get Data Demo\n",
    "#countries2=[\"AUS\",\"ARG\",\"BRA\",\"USA\"]\n",
    "#indicators2 = {'NY.GDP.PCAP.CD':'GDP per Capita', 'NY.GDP.DEFL.KD.ZG':'Inflation'}\n",
    "#df = wbdata.get_dataframe(indicators2, country=countries2, convert_date=False)\n",
    "#dfu = df.unstack(level=0)\n",
    "#plt.figure(figsize=(15,5))\n",
    "#plt.subplot(121)\n",
    "#plt.plot(dfu['GDP per Capita']);plt.title('GDP per Capita');plt.xlabel('Date');\n",
    "#plt.legend(dfu['GDP per Capita']);plt.xticks(rotation='vertical', size=8)\n",
    "#plt.subplot(122)\n",
    "#plt.plot(dfu['Inflation'][-20:]);plt.title('Inflation');plt.xlabel('Date');\n",
    "#plt.legend(dfu['Inflation']);plt.xticks(rotation='vertical')\n",
    "#plt.show()\n",
    "#df.head()\n",
    "\n",
    "\n",
    "#Print list of indicator categories and count\n",
    "#indicator_details=wbdata.get_indicator(source=2, display=False)\n",
    "#categories={}\n",
    "#\n",
    "#for indicator in indicator_details:\n",
    "#    if len(indicator['topics'])>0:\n",
    "#        if indicator['topics'][0]['value'] in categories:\n",
    "#            categories[indicator['topics'][0]['value']]+=1\n",
    "#        else:\n",
    "#            categories[indicator['topics'][0]['value']]=1\n",
    "#\n",
    "#for category in categories:\n",
    "#    print(category, categories[category])\n",
    "\n",
    "\n",
    "#Input for the function\n",
    "countries=['AUS','CHN']\n",
    "indicators={'NY.GDP.PCAP.PP.CD':'GDP per capita, PPP (current international $)',\n",
    "               'NY.GDP.MKTP.CD':'GDP (current US$)',\n",
    "               'NY.GDP.DEFL.KD.ZG':'Inflation, GDP deflator (annual %)',\n",
    "               'DT.DOD.DSTC.IR.ZS':'Short-term debt (% of total reserves)',\n",
    "               'GC.DOD.TOTL.GD.ZS':'Central government debt, total (% of GDP)',\n",
    "               'FP.CPI.TOTL.ZG':'Inflation, consumer prices (annual %)',\n",
    "               'FI.RES.TOTL.CD':'Total reserves (includes gold, current US$)',\n",
    "               'NV.IND.TOTL.CD':'Industry (including construction), value added (current US$)',\n",
    "               'NV.IND.MANF.CD':'Manufacturing, value added (current US$)',\n",
    "               'NE.TRD.GNFS.ZS':'Trade (% of GDP)',\n",
    "               }\n",
    "\n",
    "\n",
    "data_date = (datetime.datetime(1999, 1, 1), datetime.datetime(2018, 9, 1))\n",
    "\n",
    "#To inspect indicator categories\n",
    "\n",
    "#for indicator in indicator_details:\n",
    "#    if len(indicator['topics'])>0:\n",
    "#        if indicator['topics'][0]['value']=='Health ':\n",
    "#            print(\"'\",indicator['id'],\"'\",':',\"'\", indicator['name'],\"'\", sep='')\n",
    "\n",
    "\n",
    "#Get the data\n",
    "def get_wbdataframe(indicators, data_date, countries):\n",
    "    df=wbdata.get_dataframe(indicators=indicators, \n",
    "                            data_date=data_date, \n",
    "                            convert_date=True, \n",
    "                            country=countries) \n",
    "    df=df.unstack(level=0)\n",
    "    df.columns=['-'.join(col).strip() for col in df.columns.values]\n",
    "    ## print(df.shape, 'Shape with null columns')\n",
    "    df=df.loc[:,(df.sum(axis=0)!=0)]\n",
    "    df=df.dropna(axis='columns', how='all')\n",
    "    ## print(df.shape, 'Shape without null columns')\n",
    "    \n",
    "    return df\n",
    "\n",
    "#df= get_wbdataframe(indicators, data_date, countries)\n",
    "\n",
    "#df.to_csv('wb_data.csv', index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "agPMSfoLQ0lD"
   },
   "outputs": [],
   "source": [
    "\n",
    "def merge_wbdata(stock,stock_abb):\n",
    "\n",
    "  #from get_wb_data import get_wbdataframe, indicators, countries, data_date\n",
    "  #stock=adjusted_data_df_original[data]\n",
    "\n",
    "  #Get Wb data from csv\n",
    "  ##wb_data=pd.read_csv('wb_data.csv', index_col=0, parse_dates=True).astype(np.float32)\n",
    "\n",
    "  #Get Wb data from api\n",
    "  wb_data=get_wbdataframe(indicators, data_date, countries)\n",
    "\n",
    "  #Create dataframe for a single stock\n",
    "  temp_df=stock.loc[stock.symbol==stock_abb]\n",
    "  temp_df.sort_index(inplace=True)\n",
    "\n",
    "  temp_df=pd.merge_asof(temp_df, wb_data, left_index=True, \n",
    "                    right_index=True, tolerance=pd.Timedelta(days=731))\n",
    "  return temp_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-o1KOsOGPeq"
   },
   "source": [
    "## Feature engineering\n",
    "\n",
    "These are taken from project proposal, but might need further revision\n",
    "\n",
    "1. Price o Normalized to a similar scale\n",
    "2. Volume\n",
    "3. Moving average: Test different periods: 5, 10, 20, 50, 100, 150, 200, 250 day periods\n",
    "4. Momentum: Change in price over periods: 1-250 days\n",
    "5. Exponentially weighted moving average: Test different periods: 5, 10, 15, 20, 25, 30 days and different exponential weights\n",
    "6. Volatily: Test different periods: 5, 10, 20, 50, 100, 150, 200, 250 day periods\n",
    "7. Autocorrelation: Test different periods. In this specific case we shall feature autocorrelation between 10-250 days.\n",
    "8. Relative Strength Index, RSI: We shall engineer RSI data for periods from 5 to 250 days.\n",
    "9. Standard deviation of price: Test different periods: 5-50 days\n",
    "10. Volume traded moving average: Test different periods: 5, 10, 20, 50, 100, 150, 200, 250 day periods\n",
    "11. On balance volume (sum volume if price increases, deduct if it decreases): Test different periods\n",
    "12. Money flow index: Similar to on-balance volume, measures volume and price. We intend to test for different periods\n",
    "13. Apart from doing extensive feature engineering we also intend to do Spectral Analysis using Fourier Transformation of stock-price time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YCQp5wCKSsKU"
   },
   "source": [
    "### Feature engineering\n",
    "\n",
    "We acknowledge Dr. M. Khushi for his assistance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i9oS-CPXfGgR"
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "## Feature engineering\n",
    "### Acknowledgment: Dr. Matloob Khushi \n",
    "#######################################\n",
    "\n",
    "## define functions to calculate technical indicators - SET 1\n",
    "\n",
    "def SMA(data,period):\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['Close'] = data\n",
    "    return np.array(temp_df.Close.rolling(period).mean())\n",
    "\n",
    "def WMA(data,period):\n",
    "    temp = []\n",
    "    for i in np.arange(0,len(data)):\n",
    "        if i < period-1:\n",
    "            temp.append(np.nan)\n",
    "        else:\n",
    "            num, denom  = 0, 0\n",
    "            for j in np.arange(0,period):\n",
    "                num += (period - j) * data[i-j]\n",
    "                denom += (period - j)\n",
    "            temp.append(num / denom)\n",
    "    return np.array(temp)\n",
    "\n",
    "def Momentum(data,period):\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['Close'] = data\n",
    "    return np.array(temp_df.Close - temp_df.Close.shift(period))\n",
    "\n",
    "def Stochastic_K(close,high,low,period=14):\n",
    "#     %K = 100(C - L14)/(H14 - L14)\n",
    "#     Where:\n",
    "#     C = the most recent closing price\n",
    "#     L14 = the low of the 14 previous trading sessions\n",
    "#     H14 = the highest price traded during the same 14-day period\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['Close'] = close\n",
    "    temp_df['High'] = high\n",
    "    temp_df['Low'] = low\n",
    "    \n",
    "    temp_df['Sto_K'] = ((temp_df.Close - temp_df.Low.rolling(period).min()) / \\\n",
    "                        (temp_df.High.rolling(period).max() - temp_df.Low.rolling(period).min()))\n",
    "    \n",
    "    return np.array(temp_df.Sto_K.values) * 100\n",
    "\n",
    "def Stochastic_D(sto_k,period=3):\n",
    "#     %K = 100(C - L14)/(H14 - L14)\n",
    "#     Where:\n",
    "#     C = the most recent closing price\n",
    "#     L14 = the low of the 14 previous trading sessions\n",
    "#     H14 = the highest price traded during the same 14-day period\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['Sto_k'] = sto_k\n",
    "    temp_df['Sto_d'] = temp_df.Sto_k.rolling(period, center = False).mean()\n",
    "    \n",
    "    return np.array(temp_df.Sto_d.values)\n",
    "\n",
    "##  RSI function\n",
    "def RSI(data, period):\n",
    "    # data is a np array, period is size of window\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['Close'] = data\n",
    "    temp_df['Change'] = temp_df.Close - temp_df.Close.shift(1)\n",
    "    temp_df['Up'] = [i if i>=0 else np.nan for i in temp_df.Change]\n",
    "    temp_df['Down'] = [-i if i<0 else np.nan for i in temp_df.Change]\n",
    "    temp_df['Ave_gain'] = temp_df.Up.rolling(period, min_periods = 1).sum()/period\n",
    "    temp_df['Ave_loss'] = temp_df.Down.rolling(period, min_periods = 1).sum()/period\n",
    "    temp_df['RS'] = temp_df.Ave_gain / temp_df.Ave_loss\n",
    "    temp_df['RSI'] = (100 - (100 / (1 + temp_df['RS']))) \n",
    "    temp = np.array(temp_df.RSI.values)\n",
    "    temp[:period-1] = np.nan\n",
    "    \n",
    "    return temp\n",
    "\n",
    "def Williams_R(close,high,low,period=14):\n",
    "# %R = (highest high – closing price) / (highest high – lowest low) x -100\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['Close'] = close\n",
    "    temp_df['High'] = high\n",
    "    temp_df['Low'] = low\n",
    "    \n",
    "    temp_df['Wil_R'] = ((temp_df.High.rolling(period).max() - temp_df.Close) / \\\n",
    "                        (temp_df.High.rolling(period).max() - temp_df.Low.rolling(period).min()))\n",
    "    \n",
    "    return np.array(temp_df.Wil_R.values) * -100\n",
    "\n",
    "def MACD(close):\n",
    "# The MACD is calculated by subtracting the 26-day exponential moving average (EMA) \n",
    "# from the 12-day EMA. A nine-day EMA of the MACD, called the \"signal line\", is then \n",
    "# plotted on top of the MACD, functioning as a trigger for buy and sell signals\n",
    "\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['Close'] = close\n",
    "    MACD = np.array(temp_df.Close.ewm(span = 12).mean() - temp_df.Close.ewm(span = 26).mean())\n",
    "    temp_df2 = pd.DataFrame()\n",
    "    temp_df2['MACD'] = MACD\n",
    "    Signal = np.array(temp_df2.MACD.ewm(span = 9).mean())\n",
    "\n",
    "    return MACD - Signal\n",
    "\n",
    "def Accum_Ditrib(close,high,low,volume):\n",
    "# 1. Money Flow Multiplier = [(Close  -  Low) - (High - Close)] /(High - Low) \n",
    "# 2. Money Flow Volume = Money Flow Multiplier x Volume for the Period\n",
    "# 3. ADL = Previous ADL + Current Period's Money Flow Volume\n",
    "# https://stockcharts.com/school/doku.php?id=chart_school:technical_indicators:accumulation_distribution_line\n",
    "\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['Close'] = close\n",
    "    temp_df['High'] = high\n",
    "    temp_df['Low'] = low\n",
    "    temp_df['Volume'] = volume\n",
    "    \n",
    "    temp_df['MFM'] = ((temp_df.Close - temp_df.Low) - (temp_df.High - temp_df.Close)) / (temp_df.High - temp_df.Low)\n",
    "    temp_df['MFV'] = temp_df.MFM * temp_df.Volume\n",
    "    temp_df['ADL'] = np.cumsum(temp_df.MFV.values)\n",
    "    \n",
    "\n",
    "    return np.array(temp_df.ADL.values)\n",
    "\n",
    "\n",
    "def CCI(close,high,low):\n",
    "    \n",
    "# CCI = (Typical Price  -  20-period SMA of TP) / (.015 x Mean Deviation)\n",
    "# Typical Price (TP) = (High + Low + Close)/3\n",
    "# Constant = .015\n",
    "# There are four steps to calculating the Mean Deviation: \n",
    "# First, subtract the most recent 20-period average of the typical price from each period's typical price. \n",
    "# Second, take the absolute values of these numbers. \n",
    "# Third, sum the absolute values. \n",
    "# Fourth, divide by the total number of periods (20). \n",
    "# https://stockcharts.com/school/doku.php?id=chart_school:technical_indicators:commodity_channel_index_cci\n",
    "\n",
    "# The definition of overbought or oversold varies for the Commodity Channel Index (CCI). \n",
    "# ±100 may work in a trading range, but more extreme levels are needed for other situations. \n",
    "# ±200 is a much harder level to reach and more representative of a true extreme\n",
    "\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['Close'] = close\n",
    "    temp_df['High'] = high\n",
    "    temp_df['Low'] = low\n",
    "    temp_df['TP'] = temp_df['High'] + temp_df['Low'] + temp_df['Close']\n",
    "    temp_df['SMA20'] = temp_df.TP.rolling(20,center = False).mean()\n",
    "    \n",
    "    temp_df['Mean_Dev'] = np.zeros(len(temp_df))\n",
    "    for i in np.arange(0,20):\n",
    "        temp_df['Mean_Dev'] += np.abs(temp_df.TP.shift(i)-temp_df.SMA20)\n",
    "    temp_df.Mean_Dev = temp_df.Mean_Dev /20\n",
    "    \n",
    "    temp_df['CCI'] = (temp_df.TP - temp_df.SMA20) / (0.015 * temp_df.Mean_Dev)\n",
    "\n",
    "    return np.array(temp_df.CCI.values)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rBp8d9vyfGgT"
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "## Feature engineering\n",
    "### Acknowledgment: Dr. Matloob Khushi \n",
    "#######################################\n",
    "\n",
    "## define trend deterministic functions from technical indicators\n",
    "\n",
    "def T_SMA(sma, close):\n",
    "    return np.where(close>sma,1,np.where(close<sma,-1,0))\n",
    "\n",
    "def T_WMA(wma, close):\n",
    "    return np.where(close>wma,1,np.where(close<wma,-1,0))\n",
    "\n",
    "    # return +1 if sto_k at time t > sto_k at time t-1, and visa versa (0 if neither)\n",
    "def T_Sto_K(sto_k):\n",
    "    # insert 0 in front instead of np.nan\n",
    "    return np.insert(np.where(sto_k[1:]>sto_k[:-1], 1, np.where(sto_k[1:]<sto_k[:-1], -1, 0)),0,0)\n",
    "\n",
    "def T_Sto_D(sto_d):\n",
    "    # return +1 if sto_d at time t > sto_d at time t-1, and visa versa (0 if neither)\n",
    "    # insert 0 in front instead of np.nan\n",
    "    return np.insert(np.where(sto_d[1:]>sto_d[:-1], 1, np.where(sto_d[1:]<sto_d[:-1], -1, 0)),0,0)\n",
    "\n",
    "def T_Williams_R(data):\n",
    "    # return +1 if sto_d at time t > sto_d at time t-1, and visa versa (0 if neither)\n",
    "    # insert 0 in front instead of np.nan\n",
    "    return np.insert(np.where(data[1:]>data[:-1], 1, np.where(data[1:]<data[:-1], -1, 0)),0,0)\n",
    "\n",
    "def T_MACD(data):\n",
    "    # return +1 if data at time t > data at time t-1, and visa versa (0 if neither)\n",
    "    # insert 0 in front instead of np.nan\n",
    "    return np.insert(np.where(data[1:]>data[:-1], 1, np.where(data[1:]<data[:-1], -1, 0)),0,0)\n",
    "\n",
    "def T_RSI(data):\n",
    "    # If the value of RSI exceeds 70 level, it means that the stock\n",
    "    # is overbought, so, it may go down in near future (indicating opinion\n",
    "    # ‘-1’) and if the value of RSI goes below 30 level, it means that\n",
    "    # the stock is oversold, so, it may go up in near future (indicating\n",
    "    # opinion ‘+1’). For the values between (30, 70), if RSI at time ‘t’ is\n",
    "    # greater than RSI at time ‘t-1’, the opinion on trend is represented t\n",
    "    # as ‘+1’ and vice-a-versa\n",
    "    \n",
    "    return np.where(data>70,-1,np.where(data<30,1,\\\n",
    "                                       np.insert(np.where(data[1:]>data[:-1], 1, np.where(data[1:]<data[:-1], -1, 0)),0,0)\\\n",
    "                                       ))\n",
    "\n",
    "\n",
    "def T_CCI(data):\n",
    "    # CCI is also used for identifying overbought and oversold levels\n",
    "    # This means that if CCI value exceeds 200 level, the opinion for\n",
    "    # the trend is ‘-1’ and if it is below -200 level then the opinion\n",
    "    # for the trend is ‘+1’. For the values between (-200, 200), if CCI at\n",
    "    # time ‘t’ is greater than CCI at time ‘t-1’, the opinion on the trend\n",
    "    # is ‘+1’ and vice-a-versa\n",
    "    \n",
    "    return np.where(data>200,-1,np.where(data<-200,1,\\\n",
    "                                       np.insert(np.where(data[1:]>data[:-1], 1, np.where(data[1:]<data[:-1], -1, 0)),0,0)\\\n",
    "                                       ))\n",
    "\n",
    "def T_AD(data):\n",
    "    # A/D oscillator also follows the stock trend meaning that if its value at time ‘t’ \n",
    "    # is greater than that at time ‘t-1’, the opinion on trend is ‘+1’ and vice-a-versa\n",
    "    # insert 0 in front instead of np.nan\n",
    "    \n",
    "    return np.insert(np.where(data[1:]>data[:-1], 1, np.where(data[1:]<data[:-1], -1, 0)),0,0)\n",
    "\n",
    "def T_Momentum(data):\n",
    "    # Momentum measures the rate of rise and fall of stock prices. \n",
    "    # Positive value of momentum indicates up trend and is represented by ‘+1’ \n",
    "    # while negative value indicates down trend and is represented as ‘-1'\n",
    "\n",
    "    return np.where(data>0,1,np.where(data<0,-1,0))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "esPHN9tKfGgX"
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "## Feature engineering\n",
    "### Acknowledgment: Dr. Matloob Khushi \n",
    "#######################################\n",
    "\n",
    "# define functions to calculate second set of technocal indicators\n",
    "\n",
    "def OBV(close, volume):\n",
    "    theta = np.where(close[1:] > close[:-1],1,np.where(close[1:] < close[:-1],-1,0))\n",
    "    theta = np.insert(theta,0,0)\n",
    "    \n",
    "    temp = []\n",
    "    \n",
    "    for i in  np.arange(0,len(close)):\n",
    "        if i == 0:\n",
    "            temp.append(0)\n",
    "        else:\n",
    "            temp.append(temp[-1] + (theta[i] * volume[i]))\n",
    "    \n",
    "    return temp\n",
    "\n",
    "def Bias(close, period):\n",
    "    \n",
    "    ma = SMA(close,period)\n",
    "    \n",
    "    return 100 * (close - ma) / ma\n",
    "\n",
    "def ASY(close, periods):\n",
    "    \n",
    "    SY = np.insert(100 * (np.log(close[1:]) - np.log(close[:-1])),0,0)\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['SY'] = np.insert(100 * (np.log(close[1:]) - np.log(close[:-1])),0,0)\n",
    "    \n",
    "    return temp_df.SY.rolling(periods).mean()\n",
    "\n",
    "def PSY(close,period):\n",
    "    # number of rsising days in period\n",
    "    theta = np.where(close[1:] > close[:-1],1,np.where(close[1:] < close[:-1],-1,0))\n",
    "    theta = np.insert(theta,0,0)\n",
    "    \n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['rising'] = theta\n",
    "    \n",
    "    return temp_df.rising.rolling(period).sum().values / period\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9zgZQAZ6fGgZ"
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "## Feature engineering\n",
    "### Acknowledgment: Dr. Matloob Khushi \n",
    "#######################################\n",
    "\n",
    "# functions to determin gain or loss in future\n",
    "\n",
    "def Move(data, periods):\n",
    "    \n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['Close'] = data\n",
    "\n",
    "    return np.array(temp_df.Close.shift(-periods) / temp_df.Close)\n",
    "\n",
    "def T_Move(data):\n",
    "    # return 1 if Move (data) > 0, -1 if <0, otherwise 0\n",
    "    return np.where(data>1,1,np.where(data<1,-1,0))\n",
    "    \n",
    "def High(high, close, periods):\n",
    "    # calculat the ratio of 1) the highest price over next period days, divided by 2) current close\n",
    "    \n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['High'] = high\n",
    "    temp_df['Close'] = close\n",
    "\n",
    "    return np.array(pd.rolling_max(temp_df.High.shift(-1)[::-1], window=periods, min_periods=0)[::-1]/ temp_df.Close)\n",
    "\n",
    "def Low(low, close, periods):\n",
    "    # calculate the ratio of 1) the lowest price over next period days, divided by 2) current close\n",
    "    \n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['Low'] = low\n",
    "    temp_df['Close'] = close\n",
    "\n",
    "    return np.array(pd.rolling_min(temp_df.Low.shift(-1)[::-1], window=periods, min_periods=0)[::-1]/ temp_df.Close)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eql65zusPuMl"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "######################################\n",
    "def exponential_smoothing(data_df):\n",
    "  \n",
    "  ## Exponentially weighted Moving Average \n",
    "\n",
    "  ## Reference:\n",
    "  ## https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.ewm.html, accessed 31 August\n",
    "\n",
    "  alpha = [0.25,0.5,0.75] ## weights\n",
    "\n",
    "  for k in alpha:\n",
    "    data_df[\"EWMA-\"+str(k)] = data_df.Close.ewm(com = k).mean()\n",
    "    if np.sum(np.asarray(data_df[\"EWMA-\"+str(k)].isna() == True)) > 0:\n",
    "      data_df[\"EWMA-\"+str(k)] = data_df[\"EWMA-\"+str(k)].fillna(method = \"bfill\") ## Imputation\n",
    "    else:\n",
    "      continue\n",
    "  return data_df\n",
    "\n",
    "def volatility(data_df): \n",
    "  ## Volatility\n",
    "\n",
    "  ## References\n",
    "  ## https://chrisalbon.com/python/data_wrangling/pandas_moving_average/, accessed 31 August\n",
    "  ## https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.isna.html, accessed 31 August\n",
    "  ## https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna, accessed 31 August\n",
    "\n",
    "  periods_moving_average = [100,150,200,250]\n",
    "  for k in periods_moving_average:\n",
    "    data_df[\"Volatility-\"+str(k)] = data_df.Close.rolling(window = k).std()\n",
    "    if np.sum(np.asarray(data_df[\"Volatility-\"+str(k)].isna() == True)) > 0:\n",
    "      data_df[\"Volatility-\"+str(k)] = data_df[\"Volatility-\"+str(k)].fillna(method = \"bfill\") ## Imputation\n",
    "    else:\n",
    "      continue\n",
    "  return data_df\n",
    "    \n",
    "    \n",
    "  \n",
    "def autocorrelation(data_df):\n",
    "  ## Autocorrelation \n",
    "\n",
    "  ## References\n",
    "  ## https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.autocorr.html, 1 September\n",
    "  autocorr_array = []\n",
    "  threshold_lag = 250\n",
    "  row,col = np.shape(data_df)\n",
    "  k = 0\n",
    "  while k < row:\n",
    "    if k >= threshold_lag:\n",
    "      autocorr_array.append(0)\n",
    "    else:\n",
    "      autocorr_array.append(data_df.Close.autocorr(lag = k))\n",
    "    k = k+1\n",
    "\n",
    "  data_df[\"autocorrelation\"] = autocorr_array\n",
    "  return data_df\n",
    "\n",
    "def volume_traded_MA(data_df):\n",
    "\n",
    "  ## References\n",
    "  ## https://chrisalbon.com/python/data_wrangling/pandas_moving_average/, accessed 31 August\n",
    "  ## https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.isna.html, accessed 31 August\n",
    "  ## https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna, accessed 31 August\n",
    "\n",
    "  periods_moving_average = [100,150,200,250]\n",
    "  for k in periods_moving_average:\n",
    "    data_df[\"Volume_MA-\"+str(k)] = data_df.Volume.rolling(window = k).mean()\n",
    "    if np.sum(np.asarray(data_df[\"Volume_MA-\"+str(k)].isna() == True)) > 0:\n",
    "      data_df[\"Volume_MA-\"+str(k)] = data_df[\"Volume_MA-\"+str(k)].fillna(method = \"bfill\") ## Imputation\n",
    "    else:\n",
    "      continue\n",
    "  return data_df  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g0rQjeyQTAuN"
   },
   "source": [
    "### Technical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "fAp0snQ1FkBU",
    "outputId": "c0260bf7-8178-4a65-8dc4-1b1070066fe1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## TECHNICAL ANALYSIS:\\n\\n## VERSION 2.0 looks at last 3 days of momentum\\n## Version 2.1 looks at last 1 day of momentum which is a calculation of last 5 days of momentum (As defined in the Matloob function)\\n\\ndef candlestick_pattern(data,pattern):\\n  \\n  if pattern == \"Hammer v2.0\":\\n\\n    ## Hammer v2.0:\\n\\n    pattern_list = []\\n    alpha = 0.98\\n    beta = 0.98\\n    for i in range(3,data.shape[0]):\\n        count = 0 \\n        ## Checking Momentum\\n        for j in range(3):\\n            if data[\"T_Momentum\"][i-1-j] == -1:\\n                count = count + 1\\n        ## Must be on a downward trend (last 3 days downward). \\n        if count == 3:\\n            ## stock must trade signficantly lower than its opening during the day\\n            if data[\"Low\"][i] < alpha*data[\"Open\"][i]:\\n                ## stock must rally to close significantly above its opening\\n                if data[\"Close\"][i]*beta > data[\"Open\"][i]:\\n                    ## The tail should be at least twice the size of the candlestick body\\n                    if data[\"Open\"][i] - data[\\'Low\\'][i] >= 2*(data[\\'Close\\'][i]-data[\\'Open\\'][i]):\\n                        pattern_list.append(i)\\n    \\n    return pattern_list\\n  \\n  elif pattern == \"Shooting Star v2.0\":\\n  \\n    ## Shooting Star v2.0:\\n\\n    pattern_list = []\\n    alpha = 1.03\\n    for i in range(3,data.shape[0]):\\n        count = 0 \\n        ## Checking Momentum\\n        for j in range(3):\\n            if data[\"T_Momentum\"][i-1-j] == 1:\\n                count = count + 1\\n        ## Must be on an uptrend (last 3 days)   \\n        if count ==3:\\n            ## Stock must have a high significantly greater than its opening \\n            if data[\"High\"][i] > alpha*data[\"Open\"][i]:\\n                ## Despite this stock falls and closes lower than its opening\\n                if data[\"Close\"][i] < data[\"Open\"][i]:\\n                    ## distance between high and open must be more than twice as the body\\n                    if data[\"High\"][i] - data[\"Open\"][i] > 2*np.absolute(data[\"Open\"][i] - data[\"Close\"][i]):\\n                        pattern_list.append(i)\\n\\n    return pattern_list\\n  \\n  \\n  elif pattern == \"Three line strike v2.0\":\\n    ## Three line strike v2.0: \\n\\n    pattern_list = []\\n    for i in range(6,data.shape[0]):\\n        count = 0\\n        ## Checking Momentum\\n        for j in range(3,6):\\n            if data[\"T_Momentum\"][i-1-j] == -1:\\n                count = count + 1\\n        ## Must be in a donward trend (last 3 days)\\n        if count == 3:\\n            ## Must have 4 bars all having lower lows than the next and 4th opening even lower\\n            if data[\"Low\"][i-3] > data[\"Low\"][i-2] > data[\"Low\"][i-1] > data[\"Open\"][i]:\\n                ## Final bar must close for greater than the high of the first bar in the series\\n                if data[\"Close\"][i] > data[\"High\"][i-3]:\\n                    pattern_list.append(i)\\n    \\n    return pattern_list\\n  \\n  elif pattern == \"Morning Star v2.0\":\\n    ## Morning Star v2.0:\\n\\n    alpha = 1.03\\n    beta = 1.03\\n    pattern_list = []\\n    for i in range(5,data.shape[0]):\\n        count = 0 \\n        for j in range(2,5):\\n            if data[\"T_Momentum\"][i-1-j] == -1:\\n                count = count + 1\\n        ## Must be in a downtrend\\n        if count == 3:\\n            ## First bar must close significantly lower than the opening\\n            if data[\"Close\"][i-2]*alpha < data[\"Open\"][i-2]:\\n                ## 2nd bar must open for less than first bar and close for less than first bar:\\n                if data[\"Open\"][i-1] < data[\"Open\"][i-2] and data[\"Close\"][i-1] < data[\"Close\"][i-2]:\\n                    ## Final bar shows a strong resergence and closes for significantly more then it opens for \\n                    if data[\"Close\"][i] > data[\"Open\"][i]*beta:\\n                        pattern_list.append(i)\\n    \\n    return pattern_list\\n  \\n  elif pattern == \"Bullish Abandoned baby v2.1\":\\n  ## Bullish Abandoned baby v2.1: \\n\\n    pattern_list = []\\n    alpha = 1.01\\n    beta = 1.01\\n    for i in range(3, data.shape[0]):\\n        ## Check the day before the pattern to see if we are on a downward trend\\n        if data[\"T_Momentum\"][i-3] == -1:\\n            ## First bar must be bearish\\n            if data[\"Close\"][i-2] < data[\"Open\"][i-2]:\\n                ## Second bar closes for lower than the lowest point of the first bar\\n                if data[\"Close\"][i-1] < data[\"Low\"][i-2]:\\n                    ## Second bar must also be a doji candle (Very small body):\\n                    if np.absolute(data[\"Close\"][i-1]-data[\"Open\"][i-1]) < 0.01*data[\"Close\"][i-1]:\\n                        ## Third bar must open for significantly greater than the 2nd bar close.\\n                        if data[\"Close\"][i-1]*alpha < data[\"Open\"][i]:\\n                            ## Finally first bar must close for significantly more than it opened for\\n                            if data[\"Close\"][i] > data[\"Open\"][i]*beta:\\n                                pattern_list.append(i)\\n  \\n    return pattern_list\\n  \\n  \\n  elif pattern == \"Morning Star v2.1\":\\n    ## Morning Star v2.1:\\n\\n    alpha = 1.03\\n    beta = 1.05\\n    pattern_list = []\\n    for i in range(3,data.shape[0]):\\n        ## Check the day before the pattern to see if we are on a downward trend\\n        if data[\"T_Momentum\"][i-3] == -1:\\n            ## First bar must close significantly lower than the opening\\n            if data[\"Close\"][i-2]*alpha < data[\"Open\"][i-2]:\\n                ## 2nd bar must gap such that its body does not touch body of prior bar:\\n                if np.max([data[\"Close\"][i-1],data[\"Open\"][i-1]]) < data[\"Close\"][i-2]:\\n                    ## Final bar shows a strong resergence and closes for significantly more then it opens for \\n                    if data[\"Close\"][i] > data[\"Open\"][i]*beta:\\n                        pattern_list.append(i)\\n\\n    return pattern_list\\n  \\n  elif pattern == \"Three line strike v2.1\":\\n  ## Three line strike v2.1: \\n\\n    pattern_list = []\\n    for i in range(4,data.shape[0]):\\n        ## Check the day before the pattern to see if we are on a downward trend\\n        if data[\"T_Momentum\"][i-4] == -1:\\n            ## Must have 4 bars all having lower lows than the next and 4th opening even lower\\n            if data[\"Low\"][i-3] > data[\"Low\"][i-2] > data[\"Low\"][i-1] > data[\"Open\"][i]:\\n                ## Final bar must close for greater than the high of the first bar in the series\\n                if data[\"Close\"][i] > data[\"High\"][i-3]:\\n                    pattern_list.append(i)\\n    \\n    return pattern_list\\n  \\n  elif pattern == \"Hammer v2.1\":\\n    ## Hammer v2.1:\\n\\n    pattern_list = []\\n    alpha = 0.98\\n    beta = 0.98\\n    for i in range(3,data.shape[0]):\\n        ## Check the day before the pattern to see if we are on a downward trend\\n        if data[\"T_Momentum\"][i-1] == -1:\\n            ## stock must trade signficantly lower than its opening during the day\\n            if data[\"Low\"][i] < alpha*data[\"Open\"][i]:\\n                ## stock must rally to close significantly above its opening\\n                if data[\"Close\"][i]*beta > data[\"Open\"][i]:\\n                    ## The tail should be at least twice the size of the candlestick body\\n                    if data[\"Open\"][i] - data[\\'Low\\'][i] >= 2*(data[\\'Close\\'][i]-data[\\'Open\\'][i]):\\n                        pattern_list.append(i)\\n    return pattern_list\\n  \\n  elif pattern == \"Shooting Star v2.1\":\\n    ## Shooting Star v2.1:\\n\\n    pattern_list = []\\n    alpha = 1.03\\n    for i in range(3,data.shape[0]):\\n         ## Check the day before the pattern to see if we are on an uptrend\\n        if data[\"T_Momentum\"][i-1] == 1:\\n            ## Stock must have a high significantly greater than its opening \\n            if data[\"High\"][i] > alpha*data[\"Open\"][i]:\\n                ## Despite this stock falls and closes lower than its opening\\n                if data[\"Close\"][i] < data[\"Open\"][i]:\\n                    ## distance between high and open must be more than twice as the body\\n                    if data[\"High\"][i] - data[\"Open\"][i] > 2*np.absolute(data[\"Open\"][i] - data[\"Close\"][i]):\\n                        pattern_list.append(i)\\n    return pattern_list\\n  \\n  else:\\n    print(\"Wrong type of candlestick pattern\")\\n    \\n\\n\\ndef results_observer(data,pattern):\\n  pattern_list = candlestick_pattern(data,pattern)\\n  ## Results observer v2.0 (Requires running one of the candlestick pattern code blocks first: \\n  closes = []\\n  new_prices = []\\n  for index in pattern_list:\\n      closes.append(data[\"Close\"][index])\\n      new_prices.append(data[\"Close\"][index+1])\\n\\n  increase_count = 0 \\n  zero_count = 0\\n  decrease_count = 0\\n  for i in range(len(new_prices)):\\n      if new_prices[i] == closes[i]:\\n          zero_count = zero_count + 1\\n      elif new_prices[i] > closes[i]:\\n          increase_count = increase_count + 1\\n      elif new_prices[i] < closes[i]:\\n          decrease_count = decrease_count + 1 \\n\\n  print(\"Increase likelihood is: \", increase_count/(len(new_prices)))\\n  print(\"No movement liklihood is: \", zero_count/(len(new_prices)))\\n  print(\"Decrease liklihood is: \", decrease_count/(len(new_prices)))\\n\\n  return {\"Increase probability\":increase_count,\"Probability of no movement\":zero_count,\"Decrease probability\":decrease_count}\\n  \\n  \\n## To convert a pattern list into a column:\\n\\ndef make_column(data,pattern,title):\\n  pattern_list = candlestick_pattern(data,pattern)\\n  column = []\\n  for i in range(data.shape[0]):\\n    if i in pattern_list:\\n      column.append(1)\\n    else:\\n      column.append(0)\\n  data[title] = column\\n  \\n## Example\\n    \\n## make_column(pattern_list, \"shooting star\")\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "## TECHNICAL ANALYSIS:\n",
    "\n",
    "## VERSION 2.0 looks at last 3 days of momentum\n",
    "## Version 2.1 looks at last 1 day of momentum which is a calculation of last 5 days of momentum (As defined in the Matloob function)\n",
    "\n",
    "def candlestick_pattern(data,pattern):\n",
    "  \n",
    "  if pattern == \"Hammer v2.0\":\n",
    "\n",
    "    ## Hammer v2.0:\n",
    "\n",
    "    pattern_list = []\n",
    "    alpha = 0.98\n",
    "    beta = 0.98\n",
    "    for i in range(3,data.shape[0]):\n",
    "        count = 0 \n",
    "        ## Checking Momentum\n",
    "        for j in range(3):\n",
    "            if data[\"T_Momentum\"][i-1-j] == -1:\n",
    "                count = count + 1\n",
    "        ## Must be on a downward trend (last 3 days downward). \n",
    "        if count == 3:\n",
    "            ## stock must trade signficantly lower than its opening during the day\n",
    "            if data[\"Low\"][i] < alpha*data[\"Open\"][i]:\n",
    "                ## stock must rally to close significantly above its opening\n",
    "                if data[\"Close\"][i]*beta > data[\"Open\"][i]:\n",
    "                    ## The tail should be at least twice the size of the candlestick body\n",
    "                    if data[\"Open\"][i] - data['Low'][i] >= 2*(data['Close'][i]-data['Open'][i]):\n",
    "                        pattern_list.append(i)\n",
    "    \n",
    "    return pattern_list\n",
    "  \n",
    "  elif pattern == \"Shooting Star v2.0\":\n",
    "  \n",
    "    ## Shooting Star v2.0:\n",
    "\n",
    "    pattern_list = []\n",
    "    alpha = 1.03\n",
    "    for i in range(3,data.shape[0]):\n",
    "        count = 0 \n",
    "        ## Checking Momentum\n",
    "        for j in range(3):\n",
    "            if data[\"T_Momentum\"][i-1-j] == 1:\n",
    "                count = count + 1\n",
    "        ## Must be on an uptrend (last 3 days)   \n",
    "        if count ==3:\n",
    "            ## Stock must have a high significantly greater than its opening \n",
    "            if data[\"High\"][i] > alpha*data[\"Open\"][i]:\n",
    "                ## Despite this stock falls and closes lower than its opening\n",
    "                if data[\"Close\"][i] < data[\"Open\"][i]:\n",
    "                    ## distance between high and open must be more than twice as the body\n",
    "                    if data[\"High\"][i] - data[\"Open\"][i] > 2*np.absolute(data[\"Open\"][i] - data[\"Close\"][i]):\n",
    "                        pattern_list.append(i)\n",
    "\n",
    "    return pattern_list\n",
    "  \n",
    "  \n",
    "  elif pattern == \"Three line strike v2.0\":\n",
    "    ## Three line strike v2.0: \n",
    "\n",
    "    pattern_list = []\n",
    "    for i in range(6,data.shape[0]):\n",
    "        count = 0\n",
    "        ## Checking Momentum\n",
    "        for j in range(3,6):\n",
    "            if data[\"T_Momentum\"][i-1-j] == -1:\n",
    "                count = count + 1\n",
    "        ## Must be in a donward trend (last 3 days)\n",
    "        if count == 3:\n",
    "            ## Must have 4 bars all having lower lows than the next and 4th opening even lower\n",
    "            if data[\"Low\"][i-3] > data[\"Low\"][i-2] > data[\"Low\"][i-1] > data[\"Open\"][i]:\n",
    "                ## Final bar must close for greater than the high of the first bar in the series\n",
    "                if data[\"Close\"][i] > data[\"High\"][i-3]:\n",
    "                    pattern_list.append(i)\n",
    "    \n",
    "    return pattern_list\n",
    "  \n",
    "  elif pattern == \"Morning Star v2.0\":\n",
    "    ## Morning Star v2.0:\n",
    "\n",
    "    alpha = 1.03\n",
    "    beta = 1.03\n",
    "    pattern_list = []\n",
    "    for i in range(5,data.shape[0]):\n",
    "        count = 0 \n",
    "        for j in range(2,5):\n",
    "            if data[\"T_Momentum\"][i-1-j] == -1:\n",
    "                count = count + 1\n",
    "        ## Must be in a downtrend\n",
    "        if count == 3:\n",
    "            ## First bar must close significantly lower than the opening\n",
    "            if data[\"Close\"][i-2]*alpha < data[\"Open\"][i-2]:\n",
    "                ## 2nd bar must open for less than first bar and close for less than first bar:\n",
    "                if data[\"Open\"][i-1] < data[\"Open\"][i-2] and data[\"Close\"][i-1] < data[\"Close\"][i-2]:\n",
    "                    ## Final bar shows a strong resergence and closes for significantly more then it opens for \n",
    "                    if data[\"Close\"][i] > data[\"Open\"][i]*beta:\n",
    "                        pattern_list.append(i)\n",
    "    \n",
    "    return pattern_list\n",
    "  \n",
    "  elif pattern == \"Bullish Abandoned baby v2.1\":\n",
    "  ## Bullish Abandoned baby v2.1: \n",
    "\n",
    "    pattern_list = []\n",
    "    alpha = 1.01\n",
    "    beta = 1.01\n",
    "    for i in range(3, data.shape[0]):\n",
    "        ## Check the day before the pattern to see if we are on a downward trend\n",
    "        if data[\"T_Momentum\"][i-3] == -1:\n",
    "            ## First bar must be bearish\n",
    "            if data[\"Close\"][i-2] < data[\"Open\"][i-2]:\n",
    "                ## Second bar closes for lower than the lowest point of the first bar\n",
    "                if data[\"Close\"][i-1] < data[\"Low\"][i-2]:\n",
    "                    ## Second bar must also be a doji candle (Very small body):\n",
    "                    if np.absolute(data[\"Close\"][i-1]-data[\"Open\"][i-1]) < 0.01*data[\"Close\"][i-1]:\n",
    "                        ## Third bar must open for significantly greater than the 2nd bar close.\n",
    "                        if data[\"Close\"][i-1]*alpha < data[\"Open\"][i]:\n",
    "                            ## Finally first bar must close for significantly more than it opened for\n",
    "                            if data[\"Close\"][i] > data[\"Open\"][i]*beta:\n",
    "                                pattern_list.append(i)\n",
    "  \n",
    "    return pattern_list\n",
    "  \n",
    "  \n",
    "  elif pattern == \"Morning Star v2.1\":\n",
    "    ## Morning Star v2.1:\n",
    "\n",
    "    alpha = 1.03\n",
    "    beta = 1.05\n",
    "    pattern_list = []\n",
    "    for i in range(3,data.shape[0]):\n",
    "        ## Check the day before the pattern to see if we are on a downward trend\n",
    "        if data[\"T_Momentum\"][i-3] == -1:\n",
    "            ## First bar must close significantly lower than the opening\n",
    "            if data[\"Close\"][i-2]*alpha < data[\"Open\"][i-2]:\n",
    "                ## 2nd bar must gap such that its body does not touch body of prior bar:\n",
    "                if np.max([data[\"Close\"][i-1],data[\"Open\"][i-1]]) < data[\"Close\"][i-2]:\n",
    "                    ## Final bar shows a strong resergence and closes for significantly more then it opens for \n",
    "                    if data[\"Close\"][i] > data[\"Open\"][i]*beta:\n",
    "                        pattern_list.append(i)\n",
    "\n",
    "    return pattern_list\n",
    "  \n",
    "  elif pattern == \"Three line strike v2.1\":\n",
    "  ## Three line strike v2.1: \n",
    "\n",
    "    pattern_list = []\n",
    "    for i in range(4,data.shape[0]):\n",
    "        ## Check the day before the pattern to see if we are on a downward trend\n",
    "        if data[\"T_Momentum\"][i-4] == -1:\n",
    "            ## Must have 4 bars all having lower lows than the next and 4th opening even lower\n",
    "            if data[\"Low\"][i-3] > data[\"Low\"][i-2] > data[\"Low\"][i-1] > data[\"Open\"][i]:\n",
    "                ## Final bar must close for greater than the high of the first bar in the series\n",
    "                if data[\"Close\"][i] > data[\"High\"][i-3]:\n",
    "                    pattern_list.append(i)\n",
    "    \n",
    "    return pattern_list\n",
    "  \n",
    "  elif pattern == \"Hammer v2.1\":\n",
    "    ## Hammer v2.1:\n",
    "\n",
    "    pattern_list = []\n",
    "    alpha = 0.98\n",
    "    beta = 0.98\n",
    "    for i in range(3,data.shape[0]):\n",
    "        ## Check the day before the pattern to see if we are on a downward trend\n",
    "        if data[\"T_Momentum\"][i-1] == -1:\n",
    "            ## stock must trade signficantly lower than its opening during the day\n",
    "            if data[\"Low\"][i] < alpha*data[\"Open\"][i]:\n",
    "                ## stock must rally to close significantly above its opening\n",
    "                if data[\"Close\"][i]*beta > data[\"Open\"][i]:\n",
    "                    ## The tail should be at least twice the size of the candlestick body\n",
    "                    if data[\"Open\"][i] - data['Low'][i] >= 2*(data['Close'][i]-data['Open'][i]):\n",
    "                        pattern_list.append(i)\n",
    "    return pattern_list\n",
    "  \n",
    "  elif pattern == \"Shooting Star v2.1\":\n",
    "    ## Shooting Star v2.1:\n",
    "\n",
    "    pattern_list = []\n",
    "    alpha = 1.03\n",
    "    for i in range(3,data.shape[0]):\n",
    "         ## Check the day before the pattern to see if we are on an uptrend\n",
    "        if data[\"T_Momentum\"][i-1] == 1:\n",
    "            ## Stock must have a high significantly greater than its opening \n",
    "            if data[\"High\"][i] > alpha*data[\"Open\"][i]:\n",
    "                ## Despite this stock falls and closes lower than its opening\n",
    "                if data[\"Close\"][i] < data[\"Open\"][i]:\n",
    "                    ## distance between high and open must be more than twice as the body\n",
    "                    if data[\"High\"][i] - data[\"Open\"][i] > 2*np.absolute(data[\"Open\"][i] - data[\"Close\"][i]):\n",
    "                        pattern_list.append(i)\n",
    "    return pattern_list\n",
    "  \n",
    "  else:\n",
    "    print(\"Wrong type of candlestick pattern\")\n",
    "    \n",
    "\n",
    "\n",
    "def results_observer(data,pattern):\n",
    "  pattern_list = candlestick_pattern(data,pattern)\n",
    "  ## Results observer v2.0 (Requires running one of the candlestick pattern code blocks first: \n",
    "  closes = []\n",
    "  new_prices = []\n",
    "  for index in pattern_list:\n",
    "      closes.append(data[\"Close\"][index])\n",
    "      new_prices.append(data[\"Close\"][index+1])\n",
    "\n",
    "  increase_count = 0 \n",
    "  zero_count = 0\n",
    "  decrease_count = 0\n",
    "  for i in range(len(new_prices)):\n",
    "      if new_prices[i] == closes[i]:\n",
    "          zero_count = zero_count + 1\n",
    "      elif new_prices[i] > closes[i]:\n",
    "          increase_count = increase_count + 1\n",
    "      elif new_prices[i] < closes[i]:\n",
    "          decrease_count = decrease_count + 1 \n",
    "\n",
    "  print(\"Increase likelihood is: \", increase_count/(len(new_prices)))\n",
    "  print(\"No movement liklihood is: \", zero_count/(len(new_prices)))\n",
    "  print(\"Decrease liklihood is: \", decrease_count/(len(new_prices)))\n",
    "\n",
    "  return {\"Increase probability\":increase_count,\"Probability of no movement\":zero_count,\"Decrease probability\":decrease_count}\n",
    "  \n",
    "  \n",
    "## To convert a pattern list into a column:\n",
    "\n",
    "def make_column(data,pattern,title):\n",
    "  pattern_list = candlestick_pattern(data,pattern)\n",
    "  column = []\n",
    "  for i in range(data.shape[0]):\n",
    "    if i in pattern_list:\n",
    "      column.append(1)\n",
    "    else:\n",
    "      column.append(0)\n",
    "  data[title] = column\n",
    "  \n",
    "## Example\n",
    "    \n",
    "## make_column(pattern_list, \"shooting star\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jEfw45JOTEYw"
   },
   "source": [
    "### feature_engineer function\n",
    "\n",
    "Compile every features from Dr. Khushi's code to merge with world bank data features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tqgu5-KlGQf7"
   },
   "outputs": [],
   "source": [
    "## A function that performs feature engineering \n",
    "## Acknowledgment: Dr. Matloob Khushi \n",
    "\n",
    "\n",
    "def feature_engineer(data_original):\n",
    "  symbol_asx = data_original.symbol\n",
    "  adjusted_data_df = data_original\n",
    "    \n",
    "  ## add columns to adjusted_data_df dataframe\n",
    "  # Name and technical indicators\n",
    "\n",
    "  adjusted_data_df['SMA'] = SMA(adjusted_data_df.Close.values,10)\n",
    "  adjusted_data_df['WMA'] = WMA(adjusted_data_df.Close.values,10)\n",
    "  adjusted_data_df['Momentum'] = Momentum(adjusted_data_df.Close.values,10)\n",
    "  adjusted_data_df['RSI'] = RSI(adjusted_data_df.Close.values,10)\n",
    "  adjusted_data_df['Sto_K'] = Stochastic_K(adjusted_data_df.Close.values,adjusted_data_df.High.values,adjusted_data_df.Low.values,14)\n",
    "  adjusted_data_df['Sto_D'] = Stochastic_D(adjusted_data_df.Sto_K.values,3)\n",
    "  adjusted_data_df['Wil_R'] = Williams_R(adjusted_data_df.Close.values,adjusted_data_df.High.values,adjusted_data_df.Low.values,14)\n",
    "  adjusted_data_df['MACD'] = MACD(adjusted_data_df.Close.values) # MACD - Signal\n",
    "  adjusted_data_df['AD'] = Accum_Ditrib(adjusted_data_df.Close.values,adjusted_data_df.High.values,adjusted_data_df.Low.values,adjusted_data_df.Volume.values)\n",
    "  adjusted_data_df['CCI'] = CCI(adjusted_data_df.Close.values,adjusted_data_df.High.values,adjusted_data_df.Low.values)\n",
    "  # Trend deterministic technical indicators\n",
    "\n",
    "  ## Could take into consideration later\n",
    "  adjusted_data_df['T_SMA'] = T_SMA(adjusted_data_df.SMA.values,adjusted_data_df.Close.values)\n",
    "  adjusted_data_df['T_WMA'] = T_WMA(adjusted_data_df.WMA.values,adjusted_data_df.Close.values)\n",
    "  adjusted_data_df['T_Sto_K'] = T_Sto_K(adjusted_data_df.Sto_K.values)\n",
    "  adjusted_data_df['T_Sto_D'] = T_Sto_D(adjusted_data_df.Sto_D.values)\n",
    "  adjusted_data_df['T_Wil_R'] = T_Williams_R(adjusted_data_df.Wil_R.values)\n",
    "  adjusted_data_df['T_MACD'] = T_MACD(adjusted_data_df.MACD.values)\n",
    "  adjusted_data_df['T_RSI'] = T_RSI(adjusted_data_df.RSI.values)\n",
    "  adjusted_data_df['T_CCI'] = T_CCI(adjusted_data_df.CCI.values)\n",
    "  adjusted_data_df['T_AD'] = T_AD(adjusted_data_df.AD.values)\n",
    "  adjusted_data_df['T_Momentum'] = T_Momentum(adjusted_data_df.Momentum.values)\n",
    "\n",
    "\n",
    "  # Set 2 Technical Indicators\n",
    "  adjusted_data_df['OBV'] = OBV(adjusted_data_df.Close.values,adjusted_data_df.Volume.values)\n",
    "  adjusted_data_df['SMA_5'] = SMA(adjusted_data_df.Close.values,5)\n",
    "  adjusted_data_df['Bias'] = Bias(adjusted_data_df.Close.values,6)\n",
    "  adjusted_data_df['PSY'] = PSY(adjusted_data_df.Close.values,12)\n",
    "  for i in np.arange(1,6): ## Removed for loops below for speed\n",
    "    adjusted_data_df['ASY'+str(i)] = ASY(adjusted_data_df.Close.values,i)\n",
    "\n",
    "    # Gain/Loss x days ahead\n",
    "    #for i in np.arange(1,11):\n",
    "    temp = \"Move\"+str(i)\n",
    "    adjusted_data_df[temp] = Move(adjusted_data_df.Close.values,i)\n",
    "\n",
    "    #for i in np.arange(1,11):\n",
    "    temp = \"T_Move\"+str(i)\n",
    "    temp1 = \"Move\"+str(i)\n",
    "    adjusted_data_df[temp] = T_Move(adjusted_data_df[temp1].values)\n",
    "\n",
    "    #for i in np.arange(1,11):\n",
    "    temp = \"High\"+str(i)\n",
    "    adjusted_data_df[temp] = High(adjusted_data_df.High.values,adjusted_data_df.Close.values,i)\n",
    "\n",
    "    #for i in np.arange(1,11):\n",
    "    temp = \"Low\"+str(i)\n",
    "    adjusted_data_df[temp] = Low(adjusted_data_df.Low.values,adjusted_data_df.Close.values,i)\n",
    "\n",
    "\n",
    "  exponential_smoothing(adjusted_data_df)\n",
    "  volatility(adjusted_data_df)\n",
    "  autocorrelation(adjusted_data_df)\n",
    "  volume_traded_MA(adjusted_data_df)\n",
    "  \n",
    "  \"\"\"\n",
    "  pattern_array = [\"Hammer v2.0\",\"Shooting Star v2.0\",\"Three line strike v2.0\",\"Morning Star v2.0\",\n",
    "                \"Bullish Abandoned baby v2.1\",\"Morning Star v2.1\",\"Three line strike v2.1\",\n",
    "                \"Hammer v2.1\",\"Shooting Star v2.1\"]\n",
    "  \n",
    "  for pattern in pattern_array:\n",
    "    adjusted_data_df[pattern] = make_column(adjusted_data_df,pattern,title = pattern)\n",
    "  \"\"\"\n",
    "  \n",
    "  return adjusted_data_df\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WGi6mycUTOaN"
   },
   "source": [
    "### Set indices for later use (training dataset)\n",
    "\n",
    "To choose which stock to train and which to test, it was agreed that random choosing be done. This is accomplished by fixing the testing data index (as mentioned before) and to choose, randomly, the training data. Since we have three S&P500 dataset, the maximum index, starting from 1, we can choose is 4. This corresponds to choosing an integer randomly from 1, 2, 3 in index_array_dataset_list (it gives the array of index from the dataset_list defined).\n",
    "\n",
    "In addition, once the index was chosen, we must also choose the subset of stocks randomly. Here, it was chosen arbitrarily the maximum stock number, which can go as high as 150 (or other desired index if needed). The index_array_name_list gives the index array for the names of stocks to choose (hence the name index_array_name_list). The size of the index (train_size) will be the size of the training data. We also chose the size of the test data to be 10. Again this can be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "_f9--2_NbuZw",
    "outputId": "dc2dd8da-6b93-457f-eb64-33c18279e694"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: This function is deprecated. Please call randint(1, 4 + 1) instead\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: This function is deprecated. Please call randint(1, 150 + 1) instead\n"
     ]
    }
   ],
   "source": [
    "## Setting indices for later use #############\n",
    "\n",
    "## Set seed for random shuffling\n",
    "np.random.seed(1)\n",
    "\n",
    "## To use with dataset_list\n",
    "## Using random integers\n",
    "## https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.random_integers.html#numpy.random.random_integers, accessed 6 October\n",
    "max_index_dataset_list = 4\n",
    "index_array_dataset_list = np.random.random_integers(low = 1, high = max_index_dataset_list)\n",
    "print(index_array_dataset_list)\n",
    "\n",
    "## To use with name_list\n",
    "## Set threshold at 200 arbitrarily\n",
    "train_size = 20 ## Training data set size\n",
    "\n",
    "## Sorting array:\n",
    "## https://www.programiz.com/python-programming/methods/built-in/sorted\n",
    "## accessed 7 October\n",
    "index_array_name_list = np.unique(sorted(np.random.random_integers(low = 1,size = train_size,high = 150),reverse = False))\n",
    "print(len(index_array_name_list))\n",
    "\n",
    "## Size of dataset to left out for testing\n",
    "test_size = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84fuacgyTZNW"
   },
   "source": [
    "### Perform feature engineering using the *feature_engineer* function\n",
    "\n",
    "To make our predictive model usable for testing data, feature engineering must be performed on both training and testing data. This means we have to loop through the testing data index (zeroth index of dataset_list) and the randomly chosen training index, which is given by index_array_dataset_list. Additionally, every stock for a given training and testing data index will also need to be feature engineered. We access the stocks via the use of name_list (name list of stocks).\n",
    "\n",
    "* Convention: Any stock will be accessed from the adjusted data by first access its name (index corresponding to the \"versions\" of S&P500 or ASX200), then the stock for that index will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "colab_type": "code",
    "id": "Fsaozt58ZDKL",
    "outputId": "458561d8-f1a9-4cd4-96f7-8b7bb6e6d006"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ASX', 'SP500_2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in greater\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in less\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in greater\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in less\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in greater\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in less\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in greater\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in less\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in greater\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in less\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in greater\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in less\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: RuntimeWarning: invalid value encountered in greater\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: RuntimeWarning: invalid value encountered in less\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in greater\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: RuntimeWarning: invalid value encountered in greater\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: RuntimeWarning: invalid value encountered in less\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: FutureWarning: pd.rolling_max is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=1,min_periods=0,center=False).max()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: FutureWarning: pd.rolling_min is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=1,min_periods=0,center=False).min()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: FutureWarning: pd.rolling_max is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=2,min_periods=0,center=False).max()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: FutureWarning: pd.rolling_min is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=2,min_periods=0,center=False).min()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: FutureWarning: pd.rolling_max is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=3,min_periods=0,center=False).max()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: FutureWarning: pd.rolling_min is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=3,min_periods=0,center=False).min()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: FutureWarning: pd.rolling_max is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=4,min_periods=0,center=False).max()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: FutureWarning: pd.rolling_min is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=4,min_periods=0,center=False).min()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: FutureWarning: pd.rolling_max is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=5,min_periods=0,center=False).max()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: FutureWarning: pd.rolling_min is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=5,min_periods=0,center=False).min()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: RuntimeWarning: divide by zero encountered in log\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in subtract\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in subtract\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "## Removing duplicates:\n",
    "## https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop_duplicates.html accessed 7 September\n",
    "\n",
    "adjusted_data_df_subset = {}\n",
    "adjusted_data_df_merge = {}\n",
    "adj_data_df_subset = {}\n",
    "\n",
    "## Recall:\n",
    "dataset_list = [\"ASX\",\"SP500_1\",\"SP500_2\",\"SP500_3\"]\n",
    "\n",
    "dataset_list = [dataset_list[0],dataset_list[index_array_dataset_list]]\n",
    "print(dataset_list)\n",
    "\n",
    "for data in dataset_list: ## Adjust this so that runtime is reduced \n",
    "  \n",
    "  ## Adjust this so that runtime is reduced \n",
    "  name_list = adjusted_data_df_original[data].symbol.drop_duplicates()[index_array_name_list]\n",
    "  \n",
    "  \n",
    "  row,col = np.shape(adjusted_data_df_original[data])\n",
    "  adjusted_data_df_subset[data] = {}\n",
    "  adjusted_data_df_merge[data] = {}\n",
    "  adj_data_df_subset[data] = {}\n",
    "\n",
    "  for name in name_list:\n",
    "    \n",
    "    \n",
    "    adjusted_data_df_subset[data][name] = adjusted_data_df_original[data].loc[adjusted_data_df_original[data].symbol == name,:]\n",
    "    adjusted_data_df_merge[data][name] = merge_wbdata(adjusted_data_df_subset[data][name],name)\n",
    "    \n",
    "    adj_data_df_subset[data][name] = feature_engineer(adjusted_data_df_merge[data][name])\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BaIzwTjITibX"
   },
   "source": [
    "### Normalize\n",
    "\n",
    "Perform normalization via the perform_normalize function. This is done \"column-wise\", and to eliminate the burden of dealing with missing values, any column with missing values are ignored. We also do not wish to overwrite the original adjusted data, so we created a dictionary to store these (adj_data_df work, which will be the adjusted data which we will work with). But we must keep the original data for accessing the stock and stock names, though original adjusted data will not be used for training purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "frwcQojMzlkJ"
   },
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "  ## Standard deviation in Numpy\n",
    "  ## https://docs.scipy.org/doc/numpy/reference/generated/numpy.std.html, accessed 17 September\n",
    "  return (data - np.mean(data))/np.std(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y2xzjYOU3riR"
   },
   "outputs": [],
   "source": [
    "## Perform normalization\n",
    "\n",
    "## Drop columns:\n",
    "## https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html\n",
    "## accessed 21 September\n",
    "\n",
    "def perform_normalize():\n",
    "  adj_data_df_work = {}\n",
    "  for data in dataset_list[:max_index_dataset_list]:\n",
    "    adj_data_df_work[data] = {}\n",
    "    name_list = adjusted_data_df_original[data].symbol.drop_duplicates()[index_array_name_list]\n",
    "    for name in name_list:\n",
    "      adj_data_df_work[data][name] = adj_data_df_subset[data][name].dropna(axis = \"columns\",how = \"any\")\n",
    "      adj_data_df_work[data][name] = adj_data_df_work[data][name].drop(columns = \"symbol\")\n",
    "      for cc in adj_data_df_work[data][name].columns:\n",
    "        adj_data_df_work[data][name][cc] = normalize(adj_data_df_work[data][name][cc])\n",
    "\n",
    "  return adj_data_df_work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Abyf8ePnrQH6"
   },
   "outputs": [],
   "source": [
    "adj_data_df_work = perform_normalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9_r5Gmi-KmR"
   },
   "outputs": [],
   "source": [
    "## A list of stock names for reference\n",
    "## Note: this is only for reference purposes.\n",
    "\n",
    "def print_keys():\n",
    "  name_store = {}\n",
    "  for data in dataset_list[:max_index_dataset_list]:\n",
    "    name_store[data] = {}\n",
    "    name_list = adjusted_data_df_original[data].symbol.drop_duplicates()[index_array_name_list]\n",
    "    for name in name_list:\n",
    "      name_store[data][name] = [data,name,np.shape(adj_data_df_work[data][name])]\n",
    "  return name_store\n",
    "\n",
    "store_name = print_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "MbzQLQ-YSyqv",
    "outputId": "84e1eae8-0daf-4cde-af40-bd1f3c05e8d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ASX': {'ASX:AST': ['ASX', 'ASX:AST', (3208, 51)],\n",
       "  'ASX:BAP': ['ASX', 'ASX:BAP', (1100, 51)],\n",
       "  'ASX:CPU': ['ASX', 'ASX:CPU', (4753, 50)],\n",
       "  'ASX:FMG': ['ASX', 'ASX:FMG', (4753, 50)],\n",
       "  'ASX:FPH': ['ASX', 'ASX:FPH', (4262, 50)],\n",
       "  'ASX:GNC': ['ASX', 'ASX:GNC', (4753, 50)],\n",
       "  'ASX:GUD': ['ASX', 'ASX:GUD', (4753, 50)],\n",
       "  'ASX:ILU': ['ASX', 'ASX:ILU', (4753, 50)],\n",
       "  'ASX:IRE': ['ASX', 'ASX:IRE', (4536, 50)],\n",
       "  'ASX:LLC': ['ASX', 'ASX:LLC', (4753, 50)],\n",
       "  'ASX:ORI': ['ASX', 'ASX:ORI', (4753, 50)],\n",
       "  'ASX:PGH': ['ASX', 'ASX:PGH', (1186, 51)],\n",
       "  'ASX:PLS': ['ASX', 'ASX:PLS', (2764, 51)],\n",
       "  'ASX:PRY': ['ASX', 'ASX:PRY', (4753, 50)],\n",
       "  'ASX:QAN': ['ASX', 'ASX:QAN', (4753, 50)],\n",
       "  'ASX:QBE': ['ASX', 'ASX:QBE', (4753, 50)],\n",
       "  'ASX:QUB': ['ASX', 'ASX:QUB', (2944, 51)],\n",
       "  'ASX:REA': ['ASX', 'ASX:REA', (4753, 50)],\n",
       "  'ASX:RIO': ['ASX', 'ASX:RIO', (4753, 50)],\n",
       "  'ASX:RRL': ['ASX', 'ASX:RRL', (4752, 50)]},\n",
       " 'SP500_2': {'HBAN': ['SP500_2', 'HBAN', (5974, 37)],\n",
       "  'HES': ['SP500_2', 'HES', (5974, 37)],\n",
       "  'INTU': ['SP500_2', 'INTU', (5974, 37)],\n",
       "  'JWN': ['SP500_2', 'JWN', (5974, 37)],\n",
       "  'KHC': ['SP500_2', 'KHC', (812, 52)],\n",
       "  'KIM': ['SP500_2', 'KIM', (5971, 37)],\n",
       "  'KR': ['SP500_2', 'KR', (5974, 37)],\n",
       "  'LH': ['SP500_2', 'LH', (5974, 37)],\n",
       "  'LYB': ['SP500_2', 'LYB', (2117, 52)],\n",
       "  'MAR': ['SP500_2', 'MAR', (5974, 37)],\n",
       "  'MU': ['SP500_2', 'MU', (5974, 37)],\n",
       "  'NDAQ': ['SP500_2', 'NDAQ', (4087, 50)],\n",
       "  'NEE': ['SP500_2', 'NEE', (5974, 37)],\n",
       "  'NFX': ['SP500_2', 'NFX', (5974, 37)],\n",
       "  'NKE': ['SP500_2', 'NKE', (5974, 37)],\n",
       "  'NKTR': ['SP500_2', 'NKTR', (5974, 37)],\n",
       "  'NLSN': ['SP500_2', 'NLSN', (1927, 52)],\n",
       "  'NOC': ['SP500_2', 'NOC', (5974, 37)],\n",
       "  'NRG': ['SP500_2', 'NRG', (3728, 50)],\n",
       "  'NTAP': ['SP500_2', 'NTAP', (5749, 37)]}}"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jHDxssVqgef2"
   },
   "source": [
    "## Exploratory analysis - Optional\n",
    "\n",
    "We cancreate plots in order to explore the attributes as part of the process of data cleaning. Since the data size is extremely large, our exploratory analysis will need to restrict to a certain subset. This section is optional, and is meant only for visual examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z9169doZCh_B",
    "outputId": "3d2e62ea-75b4-49f1-f3a3-d8a1af3cdc20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## Testing only for AAPL data\\naapl = adj_data_df_work[\"SP500_1\"][\"AAPL\"]\\naapl.columns\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Testing only for AAPL data\n",
    "aapl = adj_data_df_work[\"SP500_1\"][\"AAPL\"]\n",
    "aapl.columns\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-OuCqomGq6HV"
   },
   "source": [
    "### Assessing correlation structures - Heatmap\n",
    "\n",
    "This is to explore correlation structures and to look for clusters. If there are clusters, we could then perform some dimensionality reduction on those clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s1bsodKe0JqS"
   },
   "outputs": [],
   "source": [
    "## Function to create heatmap. This will be used to explore correlation structures\n",
    "\n",
    "def heatmap_plot(data_name,stock_abb,chosen_attr):\n",
    "  ## For \"stock_abb\": Put \"ASX:\" then put the desired stock abbreviation\n",
    "  ## adj_data_df_work is a dictionary with key = stock name, values = dataset for that stock\n",
    "  ## Chosen attribute: Numerical column index chosen\n",
    "  \n",
    "  adj_data_df = adj_data_df_work[data_name][stock_abb]\n",
    "  adj_data_df = adj_data_df.iloc[:,chosen_attr]\n",
    "  corr_mat = np.matrix(adj_data_df.corr())\n",
    "  ## Seaborn heatmap:\n",
    "  ## https://seaborn.pydata.org/generated/seaborn.heatmap.html?highlight=heatmap#seaborn.heatmap, accessed September 9\n",
    "  plt.figure(figsize = (15,15))\n",
    "  sns.heatmap(adj_data_df.corr(),annot = True)\n",
    "  plt.title(\"Heatmap plot for \"+str(stock_abb))\n",
    "  plt.show()\n",
    "\n",
    "  ## Computation of eigenvalues:\n",
    "  ## https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.eigvals.html, accessed 16 September\n",
    "  ## https://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html?highlight=correlation%20matrix, accessed 17 September\n",
    "\n",
    "def eigen_stuff(data_name,stock_abb,chosen_attr):\n",
    "  adj_data_df = adj_data_df_work[data_name][stock_abb]\n",
    "  adj_data_df = adj_data_df.iloc[:,chosen_attr]\n",
    "  evals,evec = np.linalg.eig(np.corrcoef(adj_data_df))\n",
    "  \n",
    "  ## Taking real part:\n",
    "  ## https://docs.scipy.org/doc/numpy/reference/generated/numpy.real.html, accessed 18 September\n",
    "  \n",
    "  return evals, evec\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9XbqCv08csDl",
    "outputId": "286164ed-468c-4636-dbfb-b0c927e4d9d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\naapl = adj_data_df_work[\"SP500_1\"][\"AAPL\"]\\nheatmap_plot(\"SP500_1\",\"AAPL\",range(10,24))\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "aapl = adj_data_df_work[\"SP500_1\"][\"AAPL\"]\n",
    "heatmap_plot(\"SP500_1\",\"AAPL\",range(10,24))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBDtGoYsIcmi"
   },
   "source": [
    "### Time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "iqSp9usRwueH",
    "outputId": "f8389fc2-e275-473a-bec2-820bec7e8ad4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## Plotting\\n## Idea of time series plot:\\n## http://pandas.pydata.org/pandas-docs/version/0.13/visualization.html, accessed 2 October\\nfor data in dataset_list:\\n  print(data)  \\n  for name in name_list[:4]:\\n    plt.figure(figsize = (15,8))\\n    print(adj_data_df_work[data][name].Close)\\n    sns.tsplot(adj_data_df_work[data][name].Close)\\n    plt.title(name)\\n    plt.show()\\n    \\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Plotting\n",
    "## Idea of time series plot:\n",
    "## http://pandas.pydata.org/pandas-docs/version/0.13/visualization.html, accessed 2 October\n",
    "for data in dataset_list:\n",
    "  print(data)  \n",
    "  for name in name_list[:4]:\n",
    "    plt.figure(figsize = (15,8))\n",
    "    print(adj_data_df_work[data][name].Close)\n",
    "    sns.tsplot(adj_data_df_work[data][name].Close)\n",
    "    plt.title(name)\n",
    "    plt.show()\n",
    "    \n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ASOgb7VHr8_k"
   },
   "source": [
    "## Data analysis using State-space model\n",
    "\n",
    "Sources that could be used:\n",
    "\n",
    "- https://docs.scipy.org/doc/numpy-1.10.4/reference/generated/numpy.matrix.tolist.html (accessed 5 September)\n",
    "- https://pydlm.github.io/pydlm_user_guide.html#modeling, accessed 5 September\n",
    "- https://pydlm.github.io/example1.html#dynamic-linear-regression, accessed 5 September\n",
    "- https://github.com/wwrechard/pydlm/blob/master/doc/source/pydlm_user_guide.rst, accessed 11 September\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "maYVd2uiEbvj"
   },
   "source": [
    "### Prepare data for processing with _pydlm_ package\n",
    "\n",
    "The pydlm package requires some manipulation on the structures of the data. For example, list of lists will be needed for the training response to be fed into the dlm package in order to perform dynamic linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CmrEq1b6G3Cj"
   },
   "outputs": [],
   "source": [
    "def prepare_train(data_name_train,train_size, train_data, main_data):\n",
    "\n",
    "  response_train = {}\n",
    "  feature_matrix_dd_train = {}\n",
    "\n",
    "  ## AD did not appear in ASX, so in order to have the same number of columns,\n",
    "  ## AD must also be removed for SP500_1\n",
    "  column_drop = [\"Close\",\"adjusted_close\",\"Open\",\"High\",\"Low\"]\n",
    "\n",
    "\n",
    "  ## Train on S&P500, test on ASX ########################\n",
    "  ## Create training set for S&P500\n",
    "\n",
    "  ## data_train: SP500_1\n",
    "\n",
    "  finished = 0\n",
    "\n",
    "  while finished == 0: ## While the execution is not finished\n",
    "    data = data_name_train\n",
    "    print(\"Name of training data:\",data)\n",
    "    response_train[data] = {}\n",
    "    feature_matrix_dd_train[data] = {}\n",
    "\n",
    "    ## name_list for training set\n",
    "    ## Use the first 20 indices\n",
    "\n",
    "    name_list_train = list(main_data[data].symbol.drop_duplicates()[index_array_name_list[:train_size]])\n",
    "\n",
    "    for name_tr in name_list_train: \n",
    "      response_train[data][name_tr] = list(train_data[data][name_tr].loc[:,\"Close\"])\n",
    "\n",
    "      ## Convert pandas object to list:\n",
    "      ## https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.tolist.html (accessed 21 September)\n",
    "\n",
    "      ## Drop a column\n",
    "      ## https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html (accessed 21 September)\n",
    "\n",
    "      ## Convert data type:\n",
    "      ## https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.astype.html#numpy.ndarray.astype\n",
    "      ## accessed 21 September\n",
    "      response_train[data][name_tr] = [[r] for r in train_data[data][name_tr].loc[:,\"Close\"]]\n",
    "      feature_matrix_dd_train[data][name_tr] = np.matrix(train_data[data][name_tr].drop(columns = column_drop)).astype(dtype = \"float\").tolist()\n",
    "\n",
    "    finished = finished + 1\n",
    "\n",
    "  return name_list_train, feature_matrix_dd_train, response_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZevqSRtLQJ_4"
   },
   "source": [
    "### Create data matrix for the test set (to be fed into prediction in _pydlm_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mm5bJt0NadaC"
   },
   "outputs": [],
   "source": [
    "## Create test set \n",
    "\n",
    "def prepare_test(data_name_test, test_size, test_data, main_data):\n",
    "\n",
    "  response_test = {}\n",
    "  feature_matrix_dd_test = {}\n",
    "  column_drop = [\"Close\",\"adjusted_close\",\"Open\",\"High\",\"Low\"]\n",
    "\n",
    "\n",
    "  finished = 0 \n",
    "\n",
    "  while finished == 0: ## While the execution is not finished\n",
    "    data = data_name_test\n",
    "    response_test[data] = {}\n",
    "    feature_matrix_dd_test[data] = {}\n",
    "    data = data_name_test\n",
    "\n",
    "    length_name_list_test = len(list(main_data[data].symbol.drop_duplicates()))\n",
    "    name_list_test = list(main_data[data].symbol.drop_duplicates()[index_array_name_list[:test_size]])\n",
    "\n",
    "    for name_te in name_list_test:\n",
    "      num_row = test_data[data][name_te].shape[0]\n",
    "      \n",
    "      ## data_name_test, name_list_test\n",
    "      response_test[data][name_te] = test_data[data][name_te].Close.iloc[index_array_name_list[:test_size]]\n",
    "\n",
    "      ## Convert pandas object to list:\n",
    "      ## https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.tolist.html (accessed 21 September)\n",
    "\n",
    "      ## Drop a column\n",
    "      ## https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html (accessed 21 September)\n",
    "\n",
    "      ## Convert data type:\n",
    "      ## https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.astype.html#numpy.ndarray.astype\n",
    "      ## accessed 21 September\n",
    "\n",
    "      ##\n",
    "      feature_matrix_dd_test[data][name_te] = np.matrix(test_data[data][name_te].iloc[index_array_name_list[:test_size]].\n",
    "                                                        drop(columns = column_drop)).astype(dtype = \"float\").tolist()\n",
    "    finished = finished + 1\n",
    "\n",
    "  return name_list_test, feature_matrix_dd_test, response_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vhrL2oA6E07d"
   },
   "source": [
    "### Implement the dynamic linear model to obtain prediction mean\n",
    "\n",
    "The implementation will yield the predicted mean and others such as predicted variance for the five test observations. However, for some stocks, the predicted mean will be missing. Thus, we will take on the method of imputing the mean value of the training response values for that stock. This is done in the impute_missing_pred_mean function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XRI2NogAq8yR"
   },
   "outputs": [],
   "source": [
    "def run_state_space(data_name_train, train_size, train_data, main_data):\n",
    "  \n",
    "  name_list_train, feature_matrix_dd_train, response_train = prepare_train(data_name_train, train_size, train_data, main_data)\n",
    "\n",
    "  ## This stores the dlm object, and this will be indexed by stock names in training data\n",
    "  mydlm = {}\n",
    "\n",
    "\n",
    "  name_list_train = list(main_data[data].symbol.drop_duplicates()[index_array_name_list[:train_size]])\n",
    "\n",
    "  for name_tr in name_list_train: \n",
    "    print(\"=========\",name_tr,\"============\")\n",
    "\n",
    "    mydlm[name_tr] = {}\n",
    "\n",
    "    mydlm[name_tr] = dlm(response_train[data][name_tr]) + dynamic(features = \n",
    "                                                                 feature_matrix_dd_train[data][name_tr],\n",
    "                                                                 discount = 1,name = name_tr)\n",
    "    mydlm[name_tr].fitForwardFilter()\n",
    "   \n",
    "  return name_list_train, mydlm, response_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9QmwLJhtWRln"
   },
   "source": [
    "### A look at the latent states ($\\beta$ coefficients)\n",
    "\n",
    "These coefficients correspond to \"slope\". We will use the last coefficient, because this will correspond to the latest update of the states. Note that prediction for testing data corresponds to (feature matrix for testing data) * (latest state estimate). _Proof might be given in the final report if required or agreed among group members_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KvJNaBPEtJ0y"
   },
   "outputs": [],
   "source": [
    "## Get coefficients for the state-space model (DLM) ###############\n",
    "\n",
    "def get_latent_state(data_name_train, train_size, train_data, main_data):\n",
    "\n",
    "  #data_train = dataset_list[1]\n",
    "  #data_name_test = dataset_list[0]\n",
    "\n",
    "  name_list_train, mydlm, response_train = run_state_space(data_name_train, train_size, train_data, main_data)\n",
    "\n",
    "  latent_coef_mean = {}\n",
    "  latent_coef_var = {}\n",
    "  our_state = {}\n",
    "\n",
    "  for name_tr in name_list_train: \n",
    "    print(\"=========\",name_tr,\"============\")\n",
    "    latent_coef_mean[name_tr] = mydlm[name_tr].getLatentState(filterType = \"forwardFilter\")\n",
    "    latent_coef_var[name_tr] = mydlm[name_tr].getLatentCov(filterType = \"forwardFilter\")\n",
    "\n",
    "    our_state[name_tr] = latent_coef_mean[name_tr][len(latent_coef_mean[name_tr])-1]\n",
    "    if np.sum(np.isnan(latent_coef_mean[name_tr]) == True) > 0:\n",
    "      our_state[name_tr] = [np.mean(response_train[data_name_train][name_tr])]*len(our_state[name_tr])\n",
    "    else:\n",
    "      our_state[name_tr] = latent_coef_mean[name_tr][len(latent_coef_mean[name_tr])-1]\n",
    "\n",
    "    our_state[name_tr] = np.reshape(our_state[name_tr],newshape = (len(our_state[name_tr]),1))\n",
    "    print(our_state[name_tr])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "  return our_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ozBwa7gB0uJJ"
   },
   "outputs": [],
   "source": [
    "def predict_test_train(data_name_train, data_name_test, test_size, test_data, train_size, train_data, main_data):\n",
    "  \n",
    "  name_list_test, feature_matrix_dd_test, response_test = prepare_test(data_name_test,test_size,test_data,main_data)\n",
    "  name_list_train, feature_matrix_dd_train, response_train = prepare_train(data_name_train,train_size,train_data,main_data)\n",
    "  \n",
    "  our_state = get_latent_state(data_name_train, train_size, train_data, main_data)\n",
    "  \n",
    "  ##data_train\n",
    "  pred_test_train = {}\n",
    "  \n",
    "  for name_te in name_list_test:\n",
    "    pred_test_train[name_te] = {} \n",
    "    for name_tr in name_list_train:\n",
    "      if np.shape(our_state[name_tr])[0] == np.shape(feature_matrix_dd_test[data_name_test][name_te])[1]:\n",
    "        pred_test_train[name_te][name_tr] = list(np.dot(feature_matrix_dd_test[data_name_test][name_te],our_state[name_tr]).flatten())\n",
    "        if np.sum(np.isnan(pred_test_train[name_te][name_tr]) == True) > 0:\n",
    "          pred_test_train[name_te][name_tr] = response_train[data_name_train][name_tr][len(response_train[data_name_train][name_tr]) - 1] + np.nan_to_num(pred_test_train[name_te][name_tr])\n",
    "      else:\n",
    "        pred_test_train[name_te][name_tr] = np.nan_to_num(our_state[name_tr]) + response_train[data_name_train][name_tr][len(response_train[data_name_train][name_tr]) - 1]\n",
    "\n",
    "  return name_list_train, name_list_test, pred_test_train, response_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r2QHcMqyFs05"
   },
   "source": [
    "### Error calculation and performance analysis\n",
    "\n",
    "We will need to see how the prediction performs against the test observations. The metric we will use are mean-squared error, mean absolute percentage error, and absolute percentage error. Each of these will be carried out twice, one for the prediction on the normalized test data, and another on the original scale.\n",
    "\n",
    "To undertake performance analysis on the original scale, we multiply the predictions with the standard deviation of the original close values (for each stock), and add the mean, again from the original close values. This is an inverse transformation that brings the prediction into the original space from the normalized space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z0OVUXsk9eKc"
   },
   "outputs": [],
   "source": [
    "## Compute error and fill in missing values (NaN)\n",
    "## It is assumed that if missing values occur, then it can be replaced\n",
    "## by the mean value\n",
    "\n",
    "def error_MSE(pred,truth):\n",
    "  error_sq = [(p-t)**2 for p,t in zip(pred,truth)]\n",
    "  MSE = np.mean(error_sq)\n",
    "  return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZVPrpCngkRsc"
   },
   "outputs": [],
   "source": [
    "## De-normalize - to get to the original scale\n",
    "\n",
    "def get_parameter(data_name_test,name_test):\n",
    "  ## Standard deviation in Numpy\n",
    "  ## https://docs.scipy.org/doc/numpy/reference/generated/numpy.std.html, accessed 17 September\n",
    "  std = np.std(adj_data_df_subset[data_name_test][name_test].loc[:,\"Close\"])\n",
    "  mean = np.mean(adj_data_df_subset[data_name_test][name_test].loc[:,\"Close\"])\n",
    "  \n",
    "  return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mK9qya09iw2d"
   },
   "outputs": [],
   "source": [
    "def MSE_on_normalize(data_name_train, data_name_test, test_size, test_data, train_size, train_data, main_data):\n",
    "\n",
    "  name_list_train, name_list_test, prediction_mean_imp, response_test = predict_test_train(data_name_train, data_name_test, test_size, test_data, train_size, train_data, main_data)\n",
    "\n",
    "  MSE_error_pred = {}\n",
    "\n",
    "  for name_te in name_list_test: \n",
    "    MSE_error_pred[name_te] = {}\n",
    "    for name_tr in name_list_train:\n",
    "      MSE_error_pred[name_te][name_tr] = error_MSE(prediction_mean_imp[name_te][name_tr],response_test[data_name_test][name_te])\n",
    "      \n",
    "  return MSE_error_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4jdalAR0heFh"
   },
   "outputs": [],
   "source": [
    "## Prediction of stocks - Original scale\n",
    "\n",
    "def predict_test_train_original(data_name_train, data_name_test, test_size, test_data, train_size, train_data, main_data):\n",
    "\n",
    "  name_list_train, name_list_test, prediction_mean_imp, response_test = predict_test_train(data_name_train, data_name_test, test_size, test_data, train_size, train_data, main_data)\n",
    "  \n",
    "  ## MSE and RMSE\n",
    "  MSE_pred_original_scale = {}\n",
    "  RMSE_pred_original_scale = {}\n",
    "  pred_original_scale = {}\n",
    "  response_test_original_scale = {}\n",
    "\n",
    "\n",
    "  ## Original data from above (unnormalized): adjusted_data_df_subset[data][name]\n",
    "\n",
    "  ## response_test[data][name_te]\n",
    "\n",
    "  for name_te in name_list_test: \n",
    "    pred_original_scale[name_te] = {}\n",
    "    MSE_pred_original_scale[name_te] = {}\n",
    "    RMSE_pred_original_scale[name_te] = {}\n",
    "\n",
    "    std_temp, mean_temp = get_parameter(data_name_test,name_te)\n",
    "\n",
    "\n",
    "    ## Response transformed to original scale\n",
    "    response_test_original_scale[name_te] = [std_temp*y + mean_temp for y in response_test[data_name_test][name_te]]\n",
    "\n",
    "    for name_tr in name_list_train:    \n",
    "      pred_original_scale[name_te][name_tr] = [std_temp*y + mean_temp for y in prediction_mean_imp[name_te][name_tr]]\n",
    "\n",
    "      MSE_pred_original_scale[name_te][name_tr] = error_MSE(pred_original_scale[name_te][name_tr],response_test_original_scale[name_te])\n",
    "      RMSE_pred_original_scale[name_te][name_tr] = np.sqrt(MSE_pred_original_scale[name_te][name_tr])\n",
    "\n",
    "\n",
    "      print(\"RMSE for:\",name_tr,\"-\",name_te,\"=\",RMSE_pred_original_scale[name_te][name_tr])\n",
    "      print(\"\\n\")\n",
    "\n",
    "  return MSE_pred_original_scale, RMSE_pred_original_scale, pred_original_scale, response_test_original_scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pLWdh9tqsij1"
   },
   "source": [
    "We will create visualizations for prediction performance (RMSE and MSE). Running performance_plot will run the commands from prepare_train, and create the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y4GbJNORPmCd"
   },
   "outputs": [],
   "source": [
    "def performance_plot(data_name_train, data_name_test, test_size, test_data, train_size, train_data, main_data):\n",
    "\n",
    "  MSE_pred_original_scale, RMSE_pred_original_scale, pred_original_scale, response_test_original_scale = predict_test_train_original(data_name_train, data_name_test, test_size, test_data, train_size, train_data, main_data)\n",
    "\n",
    "  performance_data = pd.DataFrame.from_dict(RMSE_pred_original_scale)\n",
    "  for q in range(len(performance_data.columns)):\n",
    "    print(\"================\",\"RMSE:\",performance_data.columns[q],\"==================\")\n",
    "    print(\"Mean\",np.mean(performance_data.iloc[:,q]))\n",
    "    print(\"Median\",np.median(performance_data.iloc[:,q]))\n",
    "    print(\"Standard deviation\",np.std(performance_data.iloc[:,q]))\n",
    "    print(\"\\n\")\n",
    "\n",
    "  plt.figure()\n",
    "  sns.boxplot(data = performance_data,orient = \"h\")\n",
    "  plt.xlabel(\"RMSE\")\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 26456
    },
    "colab_type": "code",
    "id": "ax8l7jPs87YQ",
    "outputId": "dbb7cce7-6976-4a92-e291-677b5424cb82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of training data: SP500_2\n",
      "Name of training data: SP500_2\n",
      "========= HBAN ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= HES ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= INTU ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= JWN ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= KHC ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= KIM ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= KR ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= LH ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= LYB ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= MAR ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= MU ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= NDAQ ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= NEE ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= NFX ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= NKE ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= NKTR ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= NLSN ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= NOC ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= NRG ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= NTAP ============\n",
      "Initializing models...\n",
      "Initialization finished.\n",
      "Starting forward filtering...\n",
      "Forward filtering completed.\n",
      "========= HBAN ============\n",
      "[[-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]\n",
      " [-1.52242166e-16]]\n",
      "\n",
      "\n",
      "========= HES ============\n",
      "[[ 1.21503830e-05]\n",
      " [ 4.58270153e-05]\n",
      " [-5.99355280e-04]\n",
      " [ 6.04795601e-03]\n",
      " [ 1.07866553e-03]\n",
      " [-4.78579977e-04]\n",
      " [ 1.17035553e-03]\n",
      " [-1.67312799e-03]\n",
      " [ 1.17035553e-03]\n",
      " [ 6.70963258e-04]\n",
      " [ 8.20160091e-04]\n",
      " [ 7.63469680e-05]\n",
      " [-1.67316710e-04]\n",
      " [-6.69962313e-04]\n",
      " [-8.25865962e-05]\n",
      " [-2.17151307e-04]\n",
      " [ 5.67866037e-05]\n",
      " [ 1.95552067e-04]\n",
      " [ 2.95190666e-05]\n",
      " [ 3.08169578e-05]\n",
      " [ 3.88214874e+00]\n",
      " [-4.99209815e+00]\n",
      " [ 2.10752970e+00]\n",
      " [-2.10100901e-04]\n",
      " [-2.21156711e-04]\n",
      " [ 2.50874371e-04]\n",
      " [-1.89541680e-05]\n",
      " [ 7.41957001e-06]\n",
      " [ 1.51546534e-04]\n",
      " [ 3.15648053e-04]\n",
      " [-6.96385174e-04]\n",
      " [ 3.09596165e-04]]\n",
      "\n",
      "\n",
      "========= INTU ============\n",
      "[[ 7.46833145e-05]\n",
      " [-3.57463412e-04]\n",
      " [-3.93451408e-04]\n",
      " [-3.87809142e-04]\n",
      " [ 2.12379804e-04]\n",
      " [-1.32510821e-04]\n",
      " [ 1.09913550e-03]\n",
      " [-1.48628960e-03]\n",
      " [ 1.09913550e-03]\n",
      " [-8.70086153e-04]\n",
      " [ 8.11797497e-04]\n",
      " [ 5.32050514e-04]\n",
      " [ 1.86503915e-04]\n",
      " [ 4.65563851e-04]\n",
      " [ 4.20801237e-04]\n",
      " [ 2.68063384e-05]\n",
      " [-2.03561240e-04]\n",
      " [ 1.18218863e-04]\n",
      " [-8.18935077e-06]\n",
      " [-3.54876708e-05]\n",
      " [ 3.36360391e+00]\n",
      " [-3.71728690e+00]\n",
      " [ 1.35259304e+00]\n",
      " [ 6.62532751e-05]\n",
      " [ 9.08326315e-05]\n",
      " [-1.90042239e-04]\n",
      " [ 3.51576502e-04]\n",
      " [ 8.18268738e-06]\n",
      " [-2.81935834e-04]\n",
      " [-2.51283586e-04]\n",
      " [-8.37499526e-06]\n",
      " [ 3.93379228e-04]]\n",
      "\n",
      "\n",
      "========= JWN ============\n",
      "[[-1.73175532e-04]\n",
      " [ 2.22017777e-06]\n",
      " [-6.15922196e-04]\n",
      " [ 2.45048539e-03]\n",
      " [ 5.19532409e-04]\n",
      " [ 2.43630040e-04]\n",
      " [ 1.17100311e-03]\n",
      " [-1.79383819e-03]\n",
      " [ 1.17100311e-03]\n",
      " [ 2.19541843e-04]\n",
      " [ 8.47176469e-04]\n",
      " [ 1.78695028e-04]\n",
      " [-1.76032432e-04]\n",
      " [-5.46158024e-06]\n",
      " [ 8.18768598e-05]\n",
      " [-8.78739133e-05]\n",
      " [ 2.73200658e-04]\n",
      " [-4.19259071e-05]\n",
      " [-3.02952027e-05]\n",
      " [ 4.55536095e-05]\n",
      " [ 3.71077470e+00]\n",
      " [-4.59495047e+00]\n",
      " [ 1.88297751e+00]\n",
      " [-1.61832861e-04]\n",
      " [ 2.96931328e-04]\n",
      " [-1.27513841e-04]\n",
      " [-7.04835233e-05]\n",
      " [ 1.49506641e-06]\n",
      " [-2.98943316e-04]\n",
      " [ 3.96948241e-04]\n",
      " [-7.65062627e-04]\n",
      " [ 7.97808435e-04]]\n",
      "\n",
      "\n",
      "========= KHC ============\n",
      "[[6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]\n",
      " [6.30037894e-16]]\n",
      "\n",
      "\n",
      "========= KIM ============\n",
      "[[-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]\n",
      " [-1.52318657e-16]]\n",
      "\n",
      "\n",
      "========= KR ============\n",
      "[[-2.20471172e-04]\n",
      " [-3.33467986e-05]\n",
      " [-1.21183540e-03]\n",
      " [ 3.78664831e-03]\n",
      " [ 6.07550203e-04]\n",
      " [ 1.79329951e-04]\n",
      " [ 8.99034653e-04]\n",
      " [-1.45443825e-03]\n",
      " [ 8.99034653e-04]\n",
      " [ 3.19955894e-04]\n",
      " [ 5.96758554e-04]\n",
      " [ 5.33842261e-05]\n",
      " [-3.02173203e-04]\n",
      " [-4.51699280e-04]\n",
      " [ 1.71138804e-04]\n",
      " [-5.42869482e-05]\n",
      " [ 2.85857647e-04]\n",
      " [-1.61047887e-04]\n",
      " [ 1.60345310e-04]\n",
      " [ 5.73930001e-05]\n",
      " [ 3.78159851e+00]\n",
      " [-4.75229433e+00]\n",
      " [ 1.96905760e+00]\n",
      " [-4.21924739e-06]\n",
      " [-1.22606693e-04]\n",
      " [ 9.87527326e-05]\n",
      " [ 2.48426325e-07]\n",
      " [ 1.70291350e-05]\n",
      " [ 2.33193242e-04]\n",
      " [-5.92846027e-04]\n",
      " [ 7.76964192e-04]\n",
      " [-4.07705971e-04]]\n",
      "\n",
      "\n",
      "========= LH ============\n",
      "[[ 1.59100834e-04]\n",
      " [-1.68310924e-05]\n",
      " [-1.68722498e-04]\n",
      " [ 1.37230761e-04]\n",
      " [ 1.72851280e-04]\n",
      " [-1.08698577e-04]\n",
      " [ 8.19992130e-04]\n",
      " [-8.16023334e-04]\n",
      " [ 8.19992130e-04]\n",
      " [-3.16915426e-04]\n",
      " [ 4.39701899e-04]\n",
      " [ 7.92724031e-05]\n",
      " [-6.42563041e-05]\n",
      " [ 2.69391120e-04]\n",
      " [ 1.09544660e-04]\n",
      " [-1.96035338e-04]\n",
      " [ 1.17214934e-04]\n",
      " [ 6.38438695e-05]\n",
      " [-8.60644462e-05]\n",
      " [-1.28245540e-04]\n",
      " [ 3.39099813e+00]\n",
      " [-3.83583381e+00]\n",
      " [ 1.44422869e+00]\n",
      " [ 2.57595170e-05]\n",
      " [ 2.89012085e-04]\n",
      " [-5.76815049e-04]\n",
      " [ 3.28799690e-04]\n",
      " [-2.12441822e-05]\n",
      " [-3.00527083e-04]\n",
      " [ 3.23117088e-04]\n",
      " [-4.27476841e-05]\n",
      " [-6.64063035e-05]]\n",
      "\n",
      "\n",
      "========= LYB ============\n",
      "[[-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]\n",
      " [-3.2221116e-16]]\n",
      "\n",
      "\n",
      "========= MAR ============\n",
      "[[-2.17819834e-04]\n",
      " [ 1.71492147e-05]\n",
      " [-3.61684806e-04]\n",
      " [-9.61638587e-04]\n",
      " [ 2.01696146e-04]\n",
      " [-3.42542287e-04]\n",
      " [ 1.23684960e-03]\n",
      " [-1.42237675e-03]\n",
      " [ 1.23684960e-03]\n",
      " [-8.46049738e-04]\n",
      " [ 5.88592529e-04]\n",
      " [ 5.77277133e-04]\n",
      " [-1.05888181e-04]\n",
      " [ 4.46391648e-04]\n",
      " [ 1.62630944e-06]\n",
      " [ 1.25795930e-04]\n",
      " [-5.80851958e-05]\n",
      " [-6.47096971e-05]\n",
      " [ 5.72100602e-05]\n",
      " [-1.48510481e-04]\n",
      " [ 3.11575487e+00]\n",
      " [-3.16073963e+00]\n",
      " [ 1.04452175e+00]\n",
      " [ 9.32262287e-05]\n",
      " [-4.27547438e-05]\n",
      " [-5.75325509e-04]\n",
      " [ 6.60615390e-04]\n",
      " [-2.90160342e-05]\n",
      " [ 2.15519477e-05]\n",
      " [ 5.51077612e-04]\n",
      " [-5.09612587e-04]\n",
      " [ 7.38220335e-05]]\n",
      "\n",
      "\n",
      "========= MU ============\n",
      "[[-1.13277717e-05]\n",
      " [ 1.36031632e-05]\n",
      " [-5.54302052e-04]\n",
      " [ 2.55010999e-03]\n",
      " [ 1.83050972e-04]\n",
      " [ 3.60309979e-04]\n",
      " [ 8.62486890e-04]\n",
      " [-1.77180560e-03]\n",
      " [ 8.62486890e-04]\n",
      " [ 1.55305962e-04]\n",
      " [ 5.80281252e-04]\n",
      " [ 2.89290945e-04]\n",
      " [ 3.03715976e-04]\n",
      " [-1.20664977e-04]\n",
      " [ 6.02224818e-05]\n",
      " [ 1.26055713e-04]\n",
      " [ 6.91104488e-05]\n",
      " [-3.37599845e-04]\n",
      " [ 6.36631942e-05]\n",
      " [ 2.24000317e-04]\n",
      " [ 3.87108073e+00]\n",
      " [-4.93250730e+00]\n",
      " [ 2.06015111e+00]\n",
      " [ 1.51836661e-04]\n",
      " [-9.46744027e-05]\n",
      " [ 1.76619182e-05]\n",
      " [-1.24035325e-04]\n",
      " [ 1.55615411e-05]\n",
      " [-6.60833549e-04]\n",
      " [ 1.05091996e-03]\n",
      " [ 6.05353289e-06]\n",
      " [-4.16414677e-04]]\n",
      "\n",
      "\n",
      "========= NDAQ ============\n",
      "[[1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]\n",
      " [1.11266785e-16]]\n",
      "\n",
      "\n",
      "========= NEE ============\n",
      "[[-7.74485019e-05]\n",
      " [ 6.21744256e-05]\n",
      " [-5.63917134e-04]\n",
      " [-1.47917275e-03]\n",
      " [ 1.92495114e-04]\n",
      " [-3.08671717e-04]\n",
      " [ 1.18180055e-03]\n",
      " [-1.14098824e-03]\n",
      " [ 1.18180055e-03]\n",
      " [-1.08230534e-03]\n",
      " [ 5.23406213e-04]\n",
      " [ 6.65515016e-04]\n",
      " [-2.51119980e-04]\n",
      " [ 5.37382484e-04]\n",
      " [ 3.38943253e-04]\n",
      " [-7.50312580e-05]\n",
      " [ 2.33909832e-05]\n",
      " [-1.66130624e-04]\n",
      " [ 1.78096413e-05]\n",
      " [-1.42787617e-04]\n",
      " [ 2.95014351e+00]\n",
      " [-2.75953146e+00]\n",
      " [ 8.08831175e-01]\n",
      " [ 8.02175870e-05]\n",
      " [-5.83760983e-05]\n",
      " [-3.67669384e-05]\n",
      " [ 2.96196287e-05]\n",
      " [-2.63599015e-05]\n",
      " [ 6.59765427e-04]\n",
      " [-3.01394630e-04]\n",
      " [-6.58044767e-04]\n",
      " [ 2.15007214e-04]]\n",
      "\n",
      "\n",
      "========= NFX ============\n",
      "[[-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]\n",
      " [-4.56726499e-16]]\n",
      "\n",
      "\n",
      "========= NKE ============\n",
      "[[-1.14916969e-04]\n",
      " [ 1.43170700e-04]\n",
      " [-8.28208061e-04]\n",
      " [ 3.84931468e-03]\n",
      " [ 6.34300271e-04]\n",
      " [ 3.61216199e-04]\n",
      " [ 1.05900367e-03]\n",
      " [-1.85358363e-03]\n",
      " [ 1.05900367e-03]\n",
      " [ 5.32983475e-05]\n",
      " [ 1.09497433e-03]\n",
      " [ 5.57230333e-04]\n",
      " [-3.15529164e-04]\n",
      " [-3.16551471e-04]\n",
      " [-6.00030722e-05]\n",
      " [ 4.16214988e-04]\n",
      " [-4.06815400e-04]\n",
      " [-1.02254768e-04]\n",
      " [ 4.05404873e-05]\n",
      " [ 9.72471939e-05]\n",
      " [ 3.89579661e+00]\n",
      " [-5.01418054e+00]\n",
      " [ 2.11683513e+00]\n",
      " [-4.71097165e-04]\n",
      " [ 3.93113022e-04]\n",
      " [-7.05618697e-05]\n",
      " [-1.30144736e-04]\n",
      " [ 6.11721035e-05]\n",
      " [-1.08338504e-03]\n",
      " [ 8.29266601e-04]\n",
      " [ 1.56402976e-03]\n",
      " [-1.22980778e-03]]\n",
      "\n",
      "\n",
      "========= NKTR ============\n",
      "[[1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]\n",
      " [1.14181625e-16]]\n",
      "\n",
      "\n",
      "========= NLSN ============\n",
      "[[-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]\n",
      " [-6.19466422e-16]]\n",
      "\n",
      "\n",
      "========= NOC ============\n",
      "[[-2.52456838e-04]\n",
      " [ 1.40649892e-05]\n",
      " [-1.75214388e-04]\n",
      " [-1.73174361e-03]\n",
      " [ 1.87668284e-04]\n",
      " [-2.05545740e-04]\n",
      " [ 1.11414879e-03]\n",
      " [-1.29738085e-03]\n",
      " [ 1.11414879e-03]\n",
      " [-1.06389693e-03]\n",
      " [ 5.48982202e-04]\n",
      " [ 3.79109895e-04]\n",
      " [ 2.47419129e-05]\n",
      " [ 5.60181991e-04]\n",
      " [-3.87313508e-05]\n",
      " [ 6.16261886e-05]\n",
      " [ 4.92980955e-05]\n",
      " [-7.61058710e-05]\n",
      " [-2.27227169e-06]\n",
      " [-9.60479587e-06]\n",
      " [ 2.82920555e+00]\n",
      " [-2.49382107e+00]\n",
      " [ 6.64326110e-01]\n",
      " [ 2.81186808e-04]\n",
      " [-1.52202979e-04]\n",
      " [-3.90620180e-04]\n",
      " [ 4.32404084e-04]\n",
      " [-1.16912187e-05]\n",
      " [ 5.20530171e-04]\n",
      " [ 1.20203098e-04]\n",
      " [-1.53760371e-04]\n",
      " [-3.25301254e-04]]\n",
      "\n",
      "\n",
      "========= NRG ============\n",
      "[[6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]\n",
      " [6.09907928e-17]]\n",
      "\n",
      "\n",
      "========= NTAP ============\n",
      "[[-1.47958940e-04]\n",
      " [-2.67200728e-05]\n",
      " [-7.80914220e-04]\n",
      " [ 5.63509488e-03]\n",
      " [ 9.08884487e-04]\n",
      " [ 3.74686824e-05]\n",
      " [ 6.28504924e-04]\n",
      " [-1.34981962e-03]\n",
      " [ 6.28504924e-04]\n",
      " [ 5.98144585e-04]\n",
      " [ 6.88061524e-04]\n",
      " [-3.15341471e-05]\n",
      " [-1.02497732e-04]\n",
      " [-5.16258320e-04]\n",
      " [-1.45091538e-04]\n",
      " [ 4.17115516e-04]\n",
      " [-2.47002166e-04]\n",
      " [ 2.29184595e-04]\n",
      " [ 9.47412802e-05]\n",
      " [-6.66096350e-05]\n",
      " [ 4.13589619e+00]\n",
      " [-5.56423062e+00]\n",
      " [ 2.42606997e+00]\n",
      " [-6.66916700e-04]\n",
      " [ 4.12060619e-04]\n",
      " [ 3.53501754e-04]\n",
      " [-2.28834071e-04]\n",
      " [-3.88956716e-05]\n",
      " [-1.85543201e-03]\n",
      " [ 8.51800879e-04]\n",
      " [ 4.96417395e-04]\n",
      " [ 4.71649695e-04]]\n",
      "\n",
      "\n",
      "RMSE for: HBAN - ASX:AST = 0.1655732818165289\n",
      "\n",
      "\n",
      "RMSE for: HES - ASX:AST = 0.07366898267791488\n",
      "\n",
      "\n",
      "RMSE for: INTU - ASX:AST = 5.57824510241141\n",
      "\n",
      "\n",
      "RMSE for: JWN - ASX:AST = 1.8825937481860966\n",
      "\n",
      "\n",
      "RMSE for: KHC - ASX:AST = 2.3305534742206144\n",
      "\n",
      "\n",
      "RMSE for: KIM - ASX:AST = 1.530826980975792\n",
      "\n",
      "\n",
      "RMSE for: KR - ASX:AST = 0.20042339513480245\n",
      "\n",
      "\n",
      "RMSE for: LH - ASX:AST = 2.668950784343129\n",
      "\n",
      "\n",
      "RMSE for: LYB - ASX:AST = 1.4881906987723295\n",
      "\n",
      "\n",
      "RMSE for: MAR - ASX:AST = 3.8468475713578645\n",
      "\n",
      "\n",
      "RMSE for: MU - ASX:AST = 0.9396122541312103\n",
      "\n",
      "\n",
      "RMSE for: NDAQ - ASX:AST = 3.208051747641718\n",
      "\n",
      "\n",
      "RMSE for: NEE - ASX:AST = 4.193837409633473\n",
      "\n",
      "\n",
      "RMSE for: NFX - ASX:AST = 1.0688623549848593\n",
      "\n",
      "\n",
      "RMSE for: NKE - ASX:AST = 0.8514155020132486\n",
      "\n",
      "\n",
      "RMSE for: NKTR - ASX:AST = 3.093270379023867\n",
      "\n",
      "\n",
      "RMSE for: NLSN - ASX:AST = 1.7943851973838991\n",
      "\n",
      "\n",
      "RMSE for: NOC - ASX:AST = 3.7422540859249036\n",
      "\n",
      "\n",
      "RMSE for: NRG - ASX:AST = 0.6925502625786363\n",
      "\n",
      "\n",
      "RMSE for: NTAP - ASX:AST = 2.5952941989156635\n",
      "\n",
      "\n",
      "RMSE for: HBAN - ASX:BAP = 6.701564527544138\n",
      "\n",
      "\n",
      "RMSE for: HES - ASX:BAP = 7.0816382298486555\n",
      "\n",
      "\n",
      "RMSE for: INTU - ASX:BAP = 27.52566712512415\n",
      "\n",
      "\n",
      "RMSE for: JWN - ASX:BAP = 14.101223290104423\n",
      "\n",
      "\n",
      "RMSE for: KHC - ASX:BAP = 1.311805315118835\n",
      "\n",
      "\n",
      "RMSE for: KIM - ASX:BAP = 1.7697723478631227\n",
      "\n",
      "\n",
      "RMSE for: KR - ASX:BAP = 7.974551246947942\n",
      "\n",
      "\n",
      "RMSE for: LH - ASX:BAP = 16.957508596907633\n",
      "\n",
      "\n",
      "RMSE for: LYB - ASX:BAP = 12.668692788911551\n",
      "\n",
      "\n",
      "RMSE for: MAR - ASX:BAP = 21.236103322424018\n",
      "\n",
      "\n",
      "RMSE for: MU - ASX:BAP = 10.675540018083895\n",
      "\n",
      "\n",
      "RMSE for: NDAQ - ASX:BAP = 18.915706854338712\n",
      "\n",
      "\n",
      "RMSE for: NEE - ASX:BAP = 22.49656694991665\n",
      "\n",
      "\n",
      "RMSE for: NFX - ASX:BAP = 3.413458625293164\n",
      "\n",
      "\n",
      "RMSE for: NKE - ASX:BAP = 10.354909560972681\n",
      "\n",
      "\n",
      "RMSE for: NKTR - ASX:BAP = 18.498777759757388\n",
      "\n",
      "\n",
      "RMSE for: NLSN - ASX:BAP = 0.8944973165088647\n",
      "\n",
      "\n",
      "RMSE for: NOC - ASX:BAP = 20.85618015907519\n",
      "\n",
      "\n",
      "RMSE for: NRG - ASX:BAP = 9.777285712841\n",
      "\n",
      "\n",
      "RMSE for: NTAP - ASX:BAP = 16.68989071243572\n",
      "\n",
      "\n",
      "RMSE for: HBAN - ASX:CPU = 3.5978281682758633\n",
      "\n",
      "\n",
      "RMSE for: HES - ASX:CPU = 4.297597275945152\n",
      "\n",
      "\n",
      "RMSE for: INTU - ASX:CPU = 43.605458129059414\n",
      "\n",
      "\n",
      "RMSE for: JWN - ASX:CPU = 17.731259529461617\n",
      "\n",
      "\n",
      "RMSE for: KHC - ASX:CPU = 11.874651725124627\n",
      "\n",
      "\n",
      "RMSE for: KIM - ASX:CPU = 6.3203745462904175\n",
      "\n",
      "\n",
      "RMSE for: KR - ASX:CPU = 5.978632480710241\n",
      "\n",
      "\n",
      "RMSE for: LH - ASX:CPU = 23.23343319094297\n",
      "\n",
      "\n",
      "RMSE for: LYB - ASX:CPU = 14.97395626348179\n",
      "\n",
      "\n",
      "RMSE for: MAR - ASX:CPU = 31.4797806236005\n",
      "\n",
      "\n",
      "RMSE for: MU - ASX:CPU = 11.141965417588404\n",
      "\n",
      "\n",
      "RMSE for: NDAQ - ASX:CPU = 27.007138959294966\n",
      "\n",
      "\n",
      "RMSE for: NEE - ASX:CPU = 33.90964176280449\n",
      "\n",
      "\n",
      "RMSE for: NFX - ASX:CPU = 3.1929205466343697\n",
      "\n",
      "\n",
      "RMSE for: NKE - ASX:CPU = 10.526369253255647\n",
      "\n",
      "\n",
      "RMSE for: NKTR - ASX:CPU = 26.203593094414444\n",
      "\n",
      "\n",
      "RMSE for: NLSN - ASX:CPU = 8.143322158489221\n",
      "\n",
      "\n",
      "RMSE for: NOC - ASX:CPU = 30.747444713642697\n",
      "\n",
      "\n",
      "RMSE for: NRG - ASX:CPU = 9.419226385115515\n",
      "\n",
      "\n",
      "RMSE for: NTAP - ASX:CPU = 22.717480658770345\n",
      "\n",
      "\n",
      "RMSE for: HBAN - ASX:FPH = 2.4000196349120615\n",
      "\n",
      "\n",
      "RMSE for: HES - ASX:FPH = 2.7332538882995903\n",
      "\n",
      "\n",
      "RMSE for: INTU - ASX:FPH = 21.06607528057004\n",
      "\n",
      "\n",
      "RMSE for: JWN - ASX:FPH = 9.003908808935295\n",
      "\n",
      "\n",
      "RMSE for: KHC - ASX:FPH = 4.815027274563399\n",
      "\n",
      "\n",
      "RMSE for: KIM - ASX:FPH = 2.247417022902372\n",
      "\n",
      "\n",
      "RMSE for: KR - ASX:FPH = 3.5219814673145\n",
      "\n",
      "\n",
      "RMSE for: LH - ASX:FPH = 11.568708635585383\n",
      "\n",
      "\n",
      "RMSE for: LYB - ASX:FPH = 7.718321040845074\n",
      "\n",
      "\n",
      "RMSE for: MAR - ASX:FPH = 15.41301299471394\n",
      "\n",
      "\n",
      "RMSE for: MU - ASX:FPH = 5.931999986144514\n",
      "\n",
      "\n",
      "RMSE for: NDAQ - ASX:FPH = 13.327915978706688\n",
      "\n",
      "\n",
      "RMSE for: NEE - ASX:FPH = 16.545782455807846\n",
      "\n",
      "\n",
      "RMSE for: NFX - ASX:FPH = 0.8941716423322463\n",
      "\n",
      "\n",
      "RMSE for: NKE - ASX:FPH = 5.645058784051553\n",
      "\n",
      "\n",
      "RMSE for: NKTR - ASX:FPH = 12.953315371645827\n",
      "\n",
      "\n",
      "RMSE for: NLSN - ASX:FPH = 3.08520249465527\n",
      "\n",
      "\n",
      "RMSE for: NOC - ASX:FPH = 15.07157597606662\n",
      "\n",
      "\n",
      "RMSE for: NRG - ASX:FPH = 5.128239493848516\n",
      "\n",
      "\n",
      "RMSE for: NTAP - ASX:FPH = 11.328436902612204\n",
      "\n",
      "\n",
      "RMSE for: HBAN - ASX:FMG = 2.9883203831997265\n",
      "\n",
      "\n",
      "RMSE for: HES - ASX:FMG = 3.2307856800277466\n",
      "\n",
      "\n",
      "RMSE for: INTU - ASX:FMG = 16.242114154336264\n",
      "\n",
      "\n",
      "RMSE for: JWN - ASX:FMG = 7.701070530021266\n",
      "\n",
      "\n",
      "RMSE for: KHC - ASX:FMG = 2.0318627639611164\n",
      "\n",
      "\n",
      "RMSE for: KIM - ASX:FMG = 0.18332257956653952\n",
      "\n",
      "\n",
      "RMSE for: KR - ASX:FMG = 3.799964081261763\n",
      "\n",
      "\n",
      "RMSE for: LH - ASX:FMG = 9.518682997041418\n",
      "\n",
      "\n",
      "RMSE for: LYB - ASX:FMG = 6.789269200107663\n",
      "\n",
      "\n",
      "RMSE for: MAR - ASX:FMG = 12.240934159139046\n",
      "\n",
      "\n",
      "RMSE for: MU - ASX:FMG = 5.520402904570792\n",
      "\n",
      "\n",
      "RMSE for: NDAQ - ASX:FMG = 10.76463212344788\n",
      "\n",
      "\n",
      "RMSE for: NEE - ASX:FMG = 13.042828155630193\n",
      "\n",
      "\n",
      "RMSE for: NFX - ASX:FMG = 0.8852452843756036\n",
      "\n",
      "\n",
      "RMSE for: NKE - ASX:FMG = 5.316247248423393\n",
      "\n",
      "\n",
      "RMSE for: NKTR - ASX:FMG = 10.499358812062862\n",
      "\n",
      "\n",
      "RMSE for: NLSN - ASX:FMG = 0.7925152760232078\n",
      "\n",
      "\n",
      "RMSE for: NOC - ASX:FMG = 11.999220551013146\n",
      "\n",
      "\n",
      "RMSE for: NRG - ASX:FMG = 4.948370210395678\n",
      "\n",
      "\n",
      "RMSE for: NTAP - ASX:FMG = 9.34841530927459\n",
      "\n",
      "\n",
      "RMSE for: HBAN - ASX:GUD = 12.934180822470044\n",
      "\n",
      "\n",
      "RMSE for: HES - ASX:GUD = 13.552037464747833\n",
      "\n",
      "\n",
      "RMSE for: INTU - ASX:GUD = 46.713798834932874\n",
      "\n",
      "\n",
      "RMSE for: JWN - ASX:GUD = 24.944983238163378\n",
      "\n",
      "\n",
      "RMSE for: KHC - ASX:GUD = 0.2697292245279727\n",
      "\n",
      "\n",
      "RMSE for: KIM - ASX:GUD = 4.854274823937995\n",
      "\n",
      "\n",
      "RMSE for: KR - ASX:GUD = 15.002573165587878\n",
      "\n",
      "\n",
      "RMSE for: LH - ASX:GUD = 29.577532674882868\n",
      "\n",
      "\n",
      "RMSE for: LYB - ASX:GUD = 22.621112020860238\n",
      "\n",
      "\n",
      "RMSE for: MAR - ASX:GUD = 36.515804915806896\n",
      "\n",
      "\n",
      "RMSE for: MU - ASX:GUD = 19.38723478413444\n",
      "\n",
      "\n",
      "RMSE for: NDAQ - ASX:GUD = 32.753102481454725\n",
      "\n",
      "\n",
      "RMSE for: NEE - ASX:GUD = 38.559623396638166\n",
      "\n",
      "\n",
      "RMSE for: NFX - ASX:GUD = 7.575304925819379\n",
      "\n",
      "\n",
      "RMSE for: NKE - ASX:GUD = 18.866914038867385\n",
      "\n",
      "\n",
      "RMSE for: NKTR - ASX:GUD = 32.076994360162395\n",
      "\n",
      "\n",
      "RMSE for: NLSN - ASX:GUD = 3.3038598655594913\n",
      "\n",
      "\n",
      "RMSE for: NOC - ASX:GUD = 35.89974370631484\n",
      "\n",
      "\n",
      "RMSE for: NRG - ASX:GUD = 17.92935980640636\n",
      "\n",
      "\n",
      "RMSE for: NTAP - ASX:GUD = 29.143547983039305\n",
      "\n",
      "\n",
      "RMSE for: HBAN - ASX:GNC = 14.397655155445904\n",
      "\n",
      "\n",
      "RMSE for: HES - ASX:GNC = 14.9503781130362\n",
      "\n",
      "\n",
      "RMSE for: INTU - ASX:GNC = 51.48392462168545\n",
      "\n",
      "\n",
      "RMSE for: JWN - ASX:GNC = 26.69067581202414\n",
      "\n",
      "\n",
      "RMSE for: KHC - ASX:GNC = 10.526234375347673\n",
      "\n",
      "\n",
      "RMSE for: KIM - ASX:GNC = 9.662126110113574\n",
      "\n",
      "\n",
      "RMSE for: KR - ASX:GNC = 16.300294961189593\n",
      "\n",
      "\n",
      "RMSE for: LH - ASX:GNC = 31.849963409752046\n",
      "\n",
      "\n",
      "RMSE for: LYB - ASX:GNC = 24.151833027864047\n",
      "\n",
      "\n",
      "RMSE for: MAR - ASX:GNC = 39.73024711746551\n",
      "\n",
      "\n",
      "RMSE for: MU - ASX:GNC = 20.707236900193983\n",
      "\n",
      "\n",
      "RMSE for: NDAQ - ASX:GNC = 35.43891611049694\n",
      "\n",
      "\n",
      "RMSE for: NEE - ASX:GNC = 42.07346210115928\n",
      "\n",
      "\n",
      "RMSE for: NFX - ASX:GNC = 10.55629782635453\n",
      "\n",
      "\n",
      "RMSE for: NKE - ASX:GNC = 20.16544969932262\n",
      "\n",
      "\n",
      "RMSE for: NKTR - ASX:GNC = 34.671908206577214\n",
      "\n",
      "\n",
      "RMSE for: NLSN - ASX:GNC = 9.606391483212787\n",
      "\n",
      "\n",
      "RMSE for: NOC - ASX:GNC = 39.02551612970017\n",
      "\n",
      "\n",
      "RMSE for: NRG - ASX:GNC = 19.19873918258002\n",
      "\n",
      "\n",
      "RMSE for: NTAP - ASX:GNC = 31.36185633588373\n",
      "\n",
      "\n",
      "RMSE for: HBAN - ASX:ILU = 6.6915228336932415\n",
      "\n",
      "\n",
      "RMSE for: HES - ASX:ILU = 7.232208678628374\n",
      "\n",
      "\n",
      "RMSE for: INTU - ASX:ILU = 37.27674304994869\n",
      "\n",
      "\n",
      "RMSE for: JWN - ASX:ILU = 17.46566147399421\n",
      "\n",
      "\n",
      "RMSE for: KHC - ASX:ILU = 5.660930680838275\n",
      "\n",
      "\n",
      "RMSE for: KIM - ASX:ILU = 2.2347585743964262\n",
      "\n",
      "\n",
      "RMSE for: KR - ASX:ILU = 8.51264555727521\n",
      "\n",
      "\n",
      "RMSE for: LH - ASX:ILU = 21.67216979174828\n",
      "\n",
      "\n",
      "RMSE for: LYB - ASX:ILU = 15.359820150608083\n",
      "\n",
      "\n",
      "RMSE for: MAR - ASX:ILU = 27.985146546901365\n",
      "\n",
      "\n",
      "RMSE for: MU - ASX:ILU = 12.438929046888337\n",
      "\n",
      "\n",
      "RMSE for: NDAQ - ASX:ILU = 24.560038378356943\n",
      "\n",
      "\n",
      "RMSE for: NEE - ASX:ILU = 29.846419563779747\n",
      "\n",
      "\n",
      "RMSE for: NFX - ASX:ILU = 2.4963894531716204\n",
      "\n",
      "\n",
      "RMSE for: NKE - ASX:ILU = 11.970394274599567\n",
      "\n",
      "\n",
      "RMSE for: NKTR - ASX:ILU = 23.944931840861525\n",
      "\n",
      "\n",
      "RMSE for: NLSN - ASX:ILU = 3.134037919804396\n",
      "\n",
      "\n",
      "RMSE for: NOC - ASX:ILU = 27.424216433004794\n",
      "\n",
      "\n",
      "RMSE for: NRG - ASX:ILU = 11.127121394084194\n",
      "\n",
      "\n",
      "RMSE for: NTAP - ASX:ILU = 21.277630625459462\n",
      "\n",
      "\n",
      "RMSE for: HBAN - ASX:IRE = 8.884383858341065\n",
      "\n",
      "\n",
      "RMSE for: HES - ASX:IRE = 9.461182344913759\n",
      "\n",
      "\n",
      "RMSE for: INTU - ASX:IRE = 40.42492699366466\n",
      "\n",
      "\n",
      "RMSE for: JWN - ASX:IRE = 20.098774700965574\n",
      "\n",
      "\n",
      "RMSE for: KHC - ASX:IRE = 3.0728849042366426\n",
      "\n",
      "\n",
      "RMSE for: KIM - ASX:IRE = 1.3509067205043495\n",
      "\n",
      "\n",
      "RMSE for: KR - ASX:IRE = 10.815509560827904\n",
      "\n",
      "\n",
      "RMSE for: LH - ASX:IRE = 24.42429799340184\n",
      "\n",
      "\n",
      "RMSE for: LYB - ASX:IRE = 17.928938318091472\n",
      "\n",
      "\n",
      "RMSE for: MAR - ASX:IRE = 30.902755112323838\n",
      "\n",
      "\n",
      "RMSE for: MU - ASX:IRE = 14.909416037598577\n",
      "\n",
      "\n",
      "RMSE for: NDAQ - ASX:IRE = 27.389413607561625\n",
      "\n",
      "\n",
      "RMSE for: NEE - ASX:IRE = 32.811128892847435\n",
      "\n",
      "\n",
      "RMSE for: NFX - ASX:IRE = 3.8825187671883348\n",
      "\n",
      "\n",
      "RMSE for: NKE - ASX:IRE = 14.423579572444403\n",
      "\n",
      "\n",
      "RMSE for: NKTR - ASX:IRE = 26.7581129539295\n",
      "\n",
      "\n",
      "RMSE for: NLSN - ASX:IRE = 0.24185712601875378\n",
      "\n",
      "\n",
      "RMSE for: NOC - ASX:IRE = 30.327520292925072\n",
      "\n",
      "\n",
      "RMSE for: NRG - ASX:IRE = 13.548213253874017\n",
      "\n",
      "\n",
      "RMSE for: NTAP - ASX:IRE = 24.019060361990967\n",
      "\n",
      "\n",
      "RMSE for: HBAN - ASX:LLC = 22.218618617817988\n",
      "\n",
      "\n",
      "RMSE for: HES - ASX:LLC = 21.17669732911666\n",
      "\n",
      "\n",
      "RMSE for: INTU - ASX:LLC = 35.12636721888\n",
      "\n",
      "\n",
      "RMSE for: JWN - ASX:LLC = 2.7033499610660923\n",
      "\n",
      "\n",
      "RMSE for: KHC - ASX:LLC = 43.83612484238287\n",
      "\n",
      "\n",
      "RMSE for: KIM - ASX:LLC = 35.86895745801198\n",
      "\n",
      "\n",
      "RMSE for: KR - ASX:LLC = 18.7335250364285\n",
      "\n",
      "\n",
      "RMSE for: LH - ASX:LLC = 6.384714601820288\n",
      "\n",
      "\n",
      "RMSE for: LYB - ASX:LLC = 6.072416555213101\n",
      "\n",
      "\n",
      "RMSE for: MAR - ASX:LLC = 17.916628751403525\n",
      "\n",
      "\n",
      "RMSE for: MU - ASX:LLC = 11.381128407405106\n",
      "\n",
      "\n",
      "RMSE for: NDAQ - ASX:LLC = 11.609549382026621\n",
      "\n",
      "\n",
      "RMSE for: NEE - ASX:LLC = 21.358506515054966\n",
      "\n",
      "\n",
      "RMSE for: NFX - ASX:LLC = 31.26714484825771\n",
      "\n",
      "\n",
      "RMSE for: NKE - ASX:LLC = 12.24917565754788\n",
      "\n",
      "\n",
      "RMSE for: NKTR - ASX:LLC = 10.484333438431596\n",
      "\n",
      "\n",
      "RMSE for: NLSN - ASX:LLC = 38.49442861677328\n",
      "\n",
      "\n",
      "RMSE for: NOC - ASX:LLC = 16.880726047030276\n",
      "\n",
      "\n",
      "RMSE for: NRG - ASX:LLC = 13.81735839960714\n",
      "\n",
      "\n",
      "RMSE for: NTAP - ASX:LLC = 5.693041473733919\n",
      "\n",
      "\n",
      "================ RMSE: ASX:AST ==================\n",
      "Mean 2.097270370606398\n",
      "Median 1.8384894727849979\n",
      "Standard deviation 1.4716008861653864\n",
      "\n",
      "\n",
      "================ RMSE: ASX:BAP ==================\n",
      "Mean 12.495067023000889\n",
      "Median 11.672116403497723\n",
      "Standard deviation 7.567629059223704\n",
      "\n",
      "\n",
      "================ RMSE: ASX:CPU ==================\n",
      "Mean 17.305103744145136\n",
      "Median 13.424303994303209\n",
      "Standard deviation 11.526376030417817\n",
      "\n",
      "\n",
      "================ RMSE: ASX:FMG ==================\n",
      "Mean 6.892178120193995\n",
      "Median 6.154836052339228\n",
      "Standard deviation 4.526693003467519\n",
      "\n",
      "\n",
      "================ RMSE: ASX:FPH ==================\n",
      "Mean 8.519971256725647\n",
      "Median 6.825160513494794\n",
      "Standard deviation 5.6401833180839755\n",
      "\n",
      "\n",
      "================ RMSE: ASX:GNC ==================\n",
      "Mean 25.12745533397027\n",
      "Median 22.429534964029017\n",
      "Standard deviation 12.154485400239551\n",
      "\n",
      "\n",
      "================ RMSE: ASX:GUD ==================\n",
      "Mean 22.124085626715722\n",
      "Median 21.004173402497337\n",
      "Standard deviation 12.615093285624647\n",
      "\n",
      "\n",
      "================ RMSE: ASX:ILU ==================\n",
      "Mean 15.915585813402135\n",
      "Median 13.89937459874821\n",
      "Standard deviation 10.084451269436256\n",
      "\n",
      "\n",
      "================ RMSE: ASX:IRE ==================\n",
      "Mean 17.783769068682492\n",
      "Median 16.419177177845025\n",
      "Standard deviation 11.293773725073928\n",
      "\n",
      "\n",
      "================ RMSE: ASX:LLC ==================\n",
      "Mean 19.163639657900475\n",
      "Median 17.3986773992169\n",
      "Standard deviation 11.714030903157198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/seaborn/categorical.py:454: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  box_data = remove_na(group_data)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAFYCAYAAAAlTUT9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBo7DGQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f16ab441da0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "performance_plot(data_name_train = dataset_list[1], \n",
    "                 data_name_test = dataset_list[0], \n",
    "                 test_size = test_size, \n",
    "                 test_data = adj_data_df_work,\n",
    "                 train_size = train_size,\n",
    "                 train_data = adj_data_df_work,\n",
    "                 main_data = adjusted_data_df_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bmjSwzHCk-SZ"
   },
   "source": [
    "## References\n",
    "\n",
    "* https://docs.scipy.org/doc/numpy/reference/generated/numpy.std.html, accessed 17 September\n",
    "* https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.astype.html#numpy.ndarray.astype, accessed 21 September\n",
    "* https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html (accessed 21 September)\n",
    "* https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.tolist.html (accessed 21 September)\n",
    "* https://docs.scipy.org/doc/numpy/reference/generated/numpy.real.html, accessed 18 September\n",
    "* https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.eigvals.html, accessed 16 September\n",
    "* https://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html?highlight=correlation%20matrix, accessed 17 September\n",
    "* https://seaborn.pydata.org/generated/seaborn.heatmap.html?highlight=heatmap#seaborn.heatmap, accessed September 9\n",
    "* https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html\n",
    "* https://docs.scipy.org/doc/numpy/reference/generated/numpy.std.html\n",
    "* https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop_duplicates.html\n",
    "* https://www.programiz.com/python-programming/methods/built-in/sorted\n",
    "* https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.random_integers.html#numpy.random.random_integers\n",
    "* https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rename.html\n",
    "* https://pythonhosted.org/PyDrive/\n",
    "\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "MAIN edition COMP5703 project code.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
